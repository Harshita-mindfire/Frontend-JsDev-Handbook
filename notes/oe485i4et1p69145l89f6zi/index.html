<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/Frontend-JsDev-Handbook/favicon.ico"/><title>Langchain</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal Knowledge Space"/><meta property="og:title" content="Langchain"/><meta property="og:description" content="Personal Knowledge Space"/><meta property="og:url" content="https://Harshita-mindfire.github.io/Frontend-JsDev-Handbook/notes/oe485i4et1p69145l89f6zi/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="12/26/2025"/><meta property="article:modified_time" content="12/26/2025"/><link rel="canonical" href="https://Harshita-mindfire.github.io/Frontend-JsDev-Handbook/notes/oe485i4et1p69145l89f6zi/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/Frontend-JsDev-Handbook/_next/static/css/d70c9756212654c3.css" as="style"/><link rel="stylesheet" href="/Frontend-JsDev-Handbook/_next/static/css/d70c9756212654c3.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/Frontend-JsDev-Handbook/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/webpack-7ae598a7290a332d.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/main-99db8cbbcbcf3a6e.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/pages/_app-e77f8b0286b3a3df.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/wmlPeTCMGkfHIk3kYfq6F/_buildManifest.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/wmlPeTCMGkfHIk3kYfq6F/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="langchain">Langchain<a aria-hidden="true" class="anchor-heading icon-link" href="#langchain"></a></h1>
<ul>
<li>open source development framework for LLM applications.</li>
<li>A framework that helps you build LLM-powered apps by handling prompts, memory, tools, and data so you don‚Äôt have to reinvent the wheel.</li>
<li>two packages: python and JS(TS)</li>
</ul>
<p>With LangChain, you get:</p>
<ul>
<li><strong>Prompt templates</strong></li>
<li><strong>Chains</strong> (step-by-step LLM workflows)</li>
<li><strong>Agents</strong> (LLM decides what tool to use)</li>
<li><strong>Memory</strong> (conversation state)</li>
<li><strong>Retrieval</strong> (RAG with vector databases)</li>
<li><strong>Tool calling</strong> (search, DBs, APIs, code)</li>
</ul>
<h2 id="memory">Memory<a aria-hidden="true" class="anchor-heading icon-link" href="#memory"></a></h2>
<p>Memory lets the app remember:</p>
<ul>
<li>Previous messages</li>
<li>User preferences</li>
<li>Intermediate steps</li>
</ul>
<p>Very useful for chatbots, assistants, and copilots.</p>
<h3 id="memory-types">Memory types<a aria-hidden="true" class="anchor-heading icon-link" href="#memory-types"></a></h3>
<p><strong>ConversationBufferMemory</strong></p>
<p>This memory allows for storing of messages and then extracts the messages in a variable.</p>
<p><strong>ConversationBufferWindowMemory</strong></p>
<p>This memory keeps a list of the interactions of the conversation over time. It only uses the last K interactions.</p>
<p><strong>ConversationTokenBufferMemory</strong></p>
<p>This memory keeps a buffer of recent interactions in memory, and uses token length rather than number of interactions to determine when to flush interactions.</p>
<p><strong>ConversationSummaryMemory</strong></p>
<p>This memory creates a summary of the conversation over time.</p>
<h3 id="additional-memory-types">Additional Memory Types<a aria-hidden="true" class="anchor-heading icon-link" href="#additional-memory-types"></a></h3>
<p><strong>Vector data memory</strong> </p>
<p>Stores text (from conversation or elsewhere) in a vector database and retrieves the most relevant blocks of text.</p>
<p><strong>Entity memories</strong></p>
<p>Using an LLM, it remembers details about specific entities.</p>
<p>You can also use multiple memories at one time.</p>
<p>E.g., Conversation memory + Entity memory to recall individuals.</p>
<p>You can also store the conversation in a conventional database (such as key-value store or SQL)</p>
<h2 id="chains">Chains<a aria-hidden="true" class="anchor-heading icon-link" href="#chains"></a></h2>
<h3 id="llm-chain">LLM Chain<a aria-hidden="true" class="anchor-heading icon-link" href="#llm-chain"></a></h3>
<p>An LLM Chain is:</p>
<blockquote>
<p>A repeatable, parameterized, composable workflow around LLM calls.</p>
<ul>
<li>LLMChain is a primitive / building-block chain.</li>
<li>wraps one prompt + one model call</li>
</ul>
</blockquote>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatOpenAI 
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate 
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMChain

llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> model<span class="token operator">=</span>llm_model<span class="token punctuation">)</span> 

prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span> <span class="token string">"What is the best name to describe \ a company that makes {product}?"</span> <span class="token punctuation">)</span> 

chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>prompt<span class="token punctuation">)</span> 
product <span class="token operator">=</span> <span class="token string">"Queen Size Sheet Set"</span> 
chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span>product<span class="token punctuation">)</span> <span class="token comment">#Royal Beddings or anything the gpt responds with</span>
</code></pre>
<h3 id="sequentialchain">SequentialChain<a aria-hidden="true" class="anchor-heading icon-link" href="#sequentialchain"></a></h3>
<ul>
<li>wires multiple chains together where o/p of one chain is i/p of the next chain.
2 types of sequential chains: </li>
<li><strong>SimpleSequentialChain</strong>: single i/p and o/p</li>
<li><strong>SequentialChain</strong>: any step of the chain can take multiple i/p and o/p</li>
</ul>
<p><strong>SimpleSequentialChain</strong></p>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> SimpleSequentialChain
llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> model<span class="token operator">=</span>llm_model<span class="token punctuation">)</span>

<span class="token comment"># prompt template 1</span>
first_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    "What <span class="token keyword">is</span> the best name to describe \
    a company that makes <span class="token punctuation">{</span>product<span class="token punctuation">}</span>?"
<span class="token punctuation">)</span>

<span class="token comment"># Chain 1</span>
chain_one <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>first_prompt<span class="token punctuation">)</span>

<span class="token comment"># prompt template 2</span>
second_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    "Write a <span class="token number">20</span> words description <span class="token keyword">for</span> the following \
    company<span class="token punctuation">:</span><span class="token punctuation">{</span>company_name<span class="token punctuation">}</span>"
<span class="token punctuation">)</span>
<span class="token comment"># chain 2</span>
chain_two <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>second_prompt<span class="token punctuation">)</span>
overall_simple_chain <span class="token operator">=</span> SimpleSequentialChain<span class="token punctuation">(</span>chains<span class="token operator">=</span><span class="token punctuation">[</span>chain_one<span class="token punctuation">,</span> chain_two<span class="token punctuation">]</span><span class="token punctuation">,</span>
overall_simple_chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span>product<span class="token punctuation">)</span>
</code></pre>
<p><strong>SequentialChain</strong></p>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> SequentialChain
llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> model<span class="token operator">=</span>llm_model<span class="token punctuation">)</span>

<span class="token comment"># prompt template 1: translate to english</span>
first_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    <span class="token string">"Translate the following review to english:"</span>
    <span class="token string">"\n\n{Review}"</span>
<span class="token punctuation">)</span>
<span class="token comment"># chain 1: input= Review and output= English_Review</span>
chain_one <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>first_prompt<span class="token punctuation">,</span> 
                     output_key<span class="token operator">=</span><span class="token string">"English_Review"</span>
                    <span class="token punctuation">)</span>
second_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    <span class="token string">"Can you summarize the following review in 1 sentence:"</span>
    <span class="token string">"\n\n{English_Review}"</span>
<span class="token punctuation">)</span>
<span class="token comment"># chain 2: input= English_Review and output= summary</span>
chain_two <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>second_prompt<span class="token punctuation">,</span> 
                     output_key<span class="token operator">=</span><span class="token string">"summary"</span>
                    <span class="token punctuation">)</span>
<span class="token comment"># prompt template 3: translate to english</span>
third_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    <span class="token string">"What language is the following review:\n\n{Review}"</span>
<span class="token punctuation">)</span>
<span class="token comment"># chain 3: input= Review and output= language</span>
chain_three <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>third_prompt<span class="token punctuation">,</span>
                       output_key<span class="token operator">=</span><span class="token string">"language"</span>
                      <span class="token punctuation">)</span>

<span class="token comment"># prompt template 4: follow up message</span>
fourth_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>
    <span class="token string">"Write a follow up response to the following "</span>
    <span class="token string">"summary in the specified language:"</span>
    <span class="token string">"\n\nSummary: {summary}\n\nLanguage: {language}"</span>
<span class="token punctuation">)</span>
<span class="token comment"># chain 4: input= summary, language and output= followup_message</span>
chain_four <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>fourth_prompt<span class="token punctuation">,</span>
                      output_key<span class="token operator">=</span><span class="token string">"followup_message"</span>
                     <span class="token punctuation">)</span>
<span class="token comment"># overall_chain: input= Review </span>
<span class="token comment"># and output= English_Review,summary, followup_message</span>
overall_chain <span class="token operator">=</span> SequentialChain<span class="token punctuation">(</span>
    chains<span class="token operator">=</span><span class="token punctuation">[</span>chain_one<span class="token punctuation">,</span> chain_two<span class="token punctuation">,</span> chain_three<span class="token punctuation">,</span> chain_four<span class="token punctuation">]</span><span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"Review"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    output_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"English_Review"</span><span class="token punctuation">,</span> <span class="token string">"summary"</span><span class="token punctuation">,</span><span class="token string">"followup_message"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

review <span class="token operator">=</span> <span class="token string">"add some review here"</span>
overall_chain<span class="token punctuation">(</span>review<span class="token punctuation">)</span>
</code></pre>
<h3 id="router-chain">Router Chain<a aria-hidden="true" class="anchor-heading icon-link" href="#router-chain"></a></h3>
<p>A Router Chain is a LangChain pattern used when you don‚Äôt want one single prompt or chain to handle every input, but instead want the system to decide which chain should run based on the input.</p>
<p>Think of it as an LLM-powered if / else or switch statement.
<strong>The core idea</strong> : Given an input, choose the most appropriate chain to handle it.
Example:
If input is a math question ‚Üí use math chain
If input is code-related ‚Üí use coding chain
If input is customer support ‚Üí use support chain
You route the request to the right specialist</p>
<h3 id="key-benefits-of-using-chain">Key benefits of using Chain<a aria-hidden="true" class="anchor-heading icon-link" href="#key-benefits-of-using-chain"></a></h3>
<p>üîπ <strong>1. Prompt templating &#x26; variable injection</strong>
This becomes powerful when: Prompts are long, Variables are many, Prompts are reused across files.</p>
<p><strong>üîπ 2. Reusability &#x26; maintainability</strong>
You define the prompt once, Instead of copy-pasting prompts everywhere.</p>
<pre class="language-py"><code class="language-py">chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">"Queen Size Sheet Set"</span><span class="token punctuation">)</span>
chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">"Organic Soap"</span><span class="token punctuation">)</span>
chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">"AI SaaS Platform"</span><span class="token punctuation">)</span>
</code></pre>
<p><strong>üîπ 3. Easy model swapping &#x26; configuration</strong>
Change model/temperature without touching your logic.</p>
<pre class="language-py"><code class="language-py">llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4"</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
</code></pre>
<p><strong>üîπ 4. Multi-step workflows (SequentialChain)</strong>
While an LLMChain represents a single step, real power comes from composing multiple LLMChains using SequentialChain, RouterChain, or Agents.</p>
<p><strong>üîπ 5. Composition(chains calling chains) with tools, memory, retrievers</strong></p>
<p>Chains can be stacked:</p>
<pre class="language-py"><code class="language-py">User Input
   ‚Üì
Summarization Chain
   ‚Üì
Translation Chain
   ‚Üì
Tone Adjustment Chain
   ‚Üì
Final Output
</code></pre>
<p>Chains can integrate: üîç Vector databases, üß† Conversation memory, üõ†Ô∏è Tools &#x26; function calling, üîÑ Retries &#x26; fallback models, üìä Tracing &#x26; observability</p>
<p>Example:</p>
<pre class="language-py"><code class="language-py">
User Question
   ‚Üì
Retrieve relevant docs
   ‚Üì
Insert into prompt
   ‚Üì
LLM answers <span class="token keyword">with</span> citations
</code></pre>
<p>This is the backbone of RAG (Retrieval-Augmented Generation).</p>
<h2 id="retrieval-rag">Retrieval (RAG)<a aria-hidden="true" class="anchor-heading icon-link" href="#retrieval-rag"></a></h2>
<p>LangChain makes it easy to:</p>
<ul>
<li>Load documents (PDFs, Notion, websites)</li>
<li>Embed them into vectors</li>
<li>Store them in a vector database</li>
<li>Retrieve relevant chunks</li>
<li>Inject them into the prompt</li>
</ul>
<p>This pattern is called <strong>Retrieval-Augmented Generation (RAG)</strong>.</p>
<h3 id="common-components-of-ragretrieval-augmented-generation">Common components of RAG(Retrieval Augmented Generation)<a aria-hidden="true" class="anchor-heading icon-link" href="#common-components-of-ragretrieval-augmented-generation"></a></h3>
<div class="mermaid">
    graph TD;
      Data-Source-->Data-Transformation;
      Data-Transformation-->Text-embedding;
      Text-embedding-->VectorStore-DB;
</div>
<ul>
<li>
<p><strong>Data-Ingestion</strong>: (Load data into langchain/Data ingestion)</p>
</li>
<li>
<p><strong>Data-Transformation</strong> : (breaking data into text chunks)</p>
</li>
<li>
<p><strong>Embedding</strong>: converting text into vectors using embedding techniques. This is required for different algorithms to run(similarity serach). </p>
</li>
<li>
<p><strong>VectorStore-DB</strong>: saving vectors into a vector DB ex: chromaDB, FAISS, ASTRADB</p>
</li>
</ul>
<p>The details are present in their invdiviual pages below</p>
<h3 id="data-ingestion">Data Ingestion:<a aria-hidden="true" class="anchor-heading icon-link" href="#data-ingestion"></a></h3>
<p><a title="Private" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank" class="private">learning.langchain.document-ingestion (Private)</a></p>
<h3 id="data-transformationtext-splitting">Data-Transformation(Text splitting)<a aria-hidden="true" class="anchor-heading icon-link" href="#data-transformationtext-splitting"></a></h3>
<p><a title="Private" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank" class="private">learning.langchain.text-splitting (Private)</a></p>
<h3 id="embeddings">Embeddings<a aria-hidden="true" class="anchor-heading icon-link" href="#embeddings"></a></h3>
<p><a title="Private" href="https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html" target="_blank" class="private">learning.langchain.embeddings (Private)</a></p>
<h2 id="tools">Tools<a aria-hidden="true" class="anchor-heading icon-link" href="#tools"></a></h2>
<p>Tools can be things like:</p>
<ul>
<li>Web search</li>
<li>SQL queries</li>
<li>Python execution</li>
<li>APIs</li>
<li>File systems</li>
</ul>
<p>LangChain gives a standard way to expose these tools to an LLM.</p>
<hr>
<strong>Children</strong>
<ol>
<li><a href="/Frontend-JsDev-Handbook/notes/duydba1xzdaypg4p9egmt3g">Document Ingestion</a></li>
<li><a href="/Frontend-JsDev-Handbook/notes/nrx71p01v1xopk4xtim8xjb">LLM-models</a></li>
<li><a href="/Frontend-JsDev-Handbook/notes/0jmd9qrvoy9orbl1n2mzxla">Simple Gen AI APP Using Langchain</a></li>
<li><a href="/Frontend-JsDev-Handbook/notes/1rujyxrb9vcc5vpxg0s0o8c">Text splitting from Documents</a></li>
<li><a href="/Frontend-JsDev-Handbook/notes/g9anqrp0zrf7ge81edgx8yo">Version-1</a></li>
<li><a href="/Frontend-JsDev-Handbook/notes/qxj02f4em65xllkz33rnbb2">embeddings</a></li>
<li><a href="/Frontend-JsDev-Handbook/notes/g8ci1ind9asxblmph23fcew">vector-store</a></li>
</ol></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#memory" title="Memory">Memory</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#memory-types" title="Memory types">Memory types</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#additional-memory-types" title="Additional Memory Types">Additional Memory Types</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#chains" title="Chains">Chains</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#llm-chain" title="LLM Chain">LLM Chain</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#sequentialchain" title="SequentialChain">SequentialChain</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#router-chain" title="Router Chain">Router Chain</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#key-benefits-of-using-chain" title="Key benefits of using Chain">Key benefits of using Chain</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#retrieval-rag" title="Retrieval (RAG)">Retrieval (RAG)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#common-components-of-ragretrieval-augmented-generation" title="Common components of RAG(Retrieval Augmented Generation)">Common components of RAG(Retrieval Augmented Generation)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#data-ingestion" title="Data Ingestion:">Data Ingestion:</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#data-transformationtext-splitting" title="Data-Transformation(Text splitting)">Data-Transformation(Text splitting)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#embeddings" title="Embeddings">Embeddings</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#tools" title="Tools">Tools</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"oe485i4et1p69145l89f6zi","title":"Langchain","desc":"","updated":1766727093332,"created":1766727093332,"custom":{},"fname":"learning.Langchain","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"a8096b4163e0e9c0cf1f9ee2eb18a7eb","links":[{"type":"wiki","from":{"fname":"learning.Langchain","id":"oe485i4et1p69145l89f6zi","vaultName":"Harshita-notes"},"value":"learning.langchain.document-ingestion","position":{"start":{"line":260,"column":1,"offset":7940},"end":{"line":260,"column":42,"offset":7981},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"learning.langchain.document-ingestion"}},{"type":"wiki","from":{"fname":"learning.Langchain","id":"oe485i4et1p69145l89f6zi","vaultName":"Harshita-notes"},"value":"learning.langchain.text-splitting","position":{"start":{"line":263,"column":1,"offset":8023},"end":{"line":263,"column":38,"offset":8060},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"learning.langchain.text-splitting"}},{"type":"wiki","from":{"fname":"learning.Langchain","id":"oe485i4et1p69145l89f6zi","vaultName":"Harshita-notes"},"value":"learning.langchain.embeddings","position":{"start":{"line":266,"column":1,"offset":8077},"end":{"line":266,"column":34,"offset":8110},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"learning.langchain.embeddings"}}],"anchors":{"memory":{"type":"header","text":"Memory","value":"memory","line":20,"column":0,"depth":2},"memory-types":{"type":"header","text":"Memory types","value":"memory-types","line":28,"column":0,"depth":3},"additional-memory-types":{"type":"header","text":"Additional Memory Types","value":"additional-memory-types","line":46,"column":0,"depth":3},"chains":{"type":"header","text":"Chains","value":"chains","line":63,"column":0,"depth":2},"llm-chain":{"type":"header","text":"LLM Chain","value":"llm-chain","line":64,"column":0,"depth":3},"sequentialchain":{"type":"header","text":"SequentialChain","value":"sequentialchain","line":86,"column":0,"depth":3},"router-chain":{"type":"header","text":"Router Chain","value":"router-chain","line":173,"column":0,"depth":3},"key-benefits-of-using-chain":{"type":"header","text":"Key benefits of using Chain","value":"key-benefits-of-using-chain","line":184,"column":0,"depth":3},"retrieval-rag":{"type":"header","text":"Retrieval (RAG)","value":"retrieval-rag","line":235,"column":0,"depth":2},"common-components-of-ragretrieval-augmented-generation":{"type":"header","text":"Common components of RAG(Retrieval Augmented Generation)","value":"common-components-of-ragretrieval-augmented-generation","line":246,"column":0,"depth":3},"data-ingestion":{"type":"header","text":"Data Ingestion:","value":"data-ingestion","line":265,"column":0,"depth":3},"data-transformationtext-splitting":{"type":"header","text":"Data-Transformation(Text splitting)","value":"data-transformationtext-splitting","line":268,"column":0,"depth":3},"embeddings":{"type":"header","text":"Embeddings","value":"embeddings","line":271,"column":0,"depth":3},"tools":{"type":"header","text":"Tools","value":"tools","line":275,"column":0,"depth":2}},"children":["duydba1xzdaypg4p9egmt3g","1rujyxrb9vcc5vpxg0s0o8c","qxj02f4em65xllkz33rnbb2","g8ci1ind9asxblmph23fcew","0jmd9qrvoy9orbl1n2mzxla","nrx71p01v1xopk4xtim8xjb","g9anqrp0zrf7ge81edgx8yo"],"parent":"trkx8xrg7g2fm023ez4ldqj","data":{}},"body":"\u003ch1 id=\"langchain\"\u003eLangchain\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#langchain\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eopen source development framework for LLM applications.\u003c/li\u003e\n\u003cli\u003eA framework that helps you build LLM-powered apps by handling prompts, memory, tools, and data so you don‚Äôt have to reinvent the wheel.\u003c/li\u003e\n\u003cli\u003etwo packages: python and JS(TS)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWith LangChain, you get:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePrompt templates\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eChains\u003c/strong\u003e (step-by-step LLM workflows)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAgents\u003c/strong\u003e (LLM decides what tool to use)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMemory\u003c/strong\u003e (conversation state)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRetrieval\u003c/strong\u003e (RAG with vector databases)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTool calling\u003c/strong\u003e (search, DBs, APIs, code)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"memory\"\u003eMemory\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#memory\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eMemory lets the app remember:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePrevious messages\u003c/li\u003e\n\u003cli\u003eUser preferences\u003c/li\u003e\n\u003cli\u003eIntermediate steps\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eVery useful for chatbots, assistants, and copilots.\u003c/p\u003e\n\u003ch3 id=\"memory-types\"\u003eMemory types\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#memory-types\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eConversationBufferMemory\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThis memory allows for storing of messages and then extracts the messages in a variable.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConversationBufferWindowMemory\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThis memory keeps a list of the interactions of the conversation over time. It only uses the last K interactions.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConversationTokenBufferMemory\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThis memory keeps a buffer of recent interactions in memory, and uses token length rather than number of interactions to determine when to flush interactions.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConversationSummaryMemory\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThis memory creates a summary of the conversation over time.\u003c/p\u003e\n\u003ch3 id=\"additional-memory-types\"\u003eAdditional Memory Types\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#additional-memory-types\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eVector data memory\u003c/strong\u003e \u003c/p\u003e\n\u003cp\u003eStores text (from conversation or elsewhere) in a vector database and retrieves the most relevant blocks of text.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eEntity memories\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eUsing an LLM, it remembers details about specific entities.\u003c/p\u003e\n\u003cp\u003eYou can also use multiple memories at one time.\u003c/p\u003e\n\u003cp\u003eE.g., Conversation memory + Entity memory to recall individuals.\u003c/p\u003e\n\u003cp\u003eYou can also store the conversation in a conventional database (such as key-value store or SQL)\u003c/p\u003e\n\u003ch2 id=\"chains\"\u003eChains\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#chains\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"llm-chain\"\u003eLLM Chain\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#llm-chain\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eAn LLM Chain is:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eA repeatable, parameterized, composable workflow around LLM calls.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLLMChain is a primitive / building-block chain.\u003c/li\u003e\n\u003cli\u003ewraps one prompt + one model call\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003echat_models \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e ChatOpenAI \n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eprompts \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e ChatPromptTemplate \n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003echains \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e LLMChain\n\nllm \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatOpenAI\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etemperature\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.9\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e model\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ellm_model\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \n\nprompt \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatPromptTemplate\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_template\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"What is the best name to describe \\ a company that makes {product}?\"\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \n\nchain \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e LLMChain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ellm\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ellm\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e prompt\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eprompt\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \nproduct \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"Queen Size Sheet Set\"\u003c/span\u003e \nchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erun\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eproduct\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#Royal Beddings or anything the gpt responds with\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"sequentialchain\"\u003eSequentialChain\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#sequentialchain\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ewires multiple chains together where o/p of one chain is i/p of the next chain.\n2 types of sequential chains: \u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSimpleSequentialChain\u003c/strong\u003e: single i/p and o/p\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSequentialChain\u003c/strong\u003e: any step of the chain can take multiple i/p and o/p\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eSimpleSequentialChain\u003c/strong\u003e\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003echains \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e SimpleSequentialChain\nllm \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatOpenAI\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etemperature\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.9\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e model\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ellm_model\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# prompt template 1\u003c/span\u003e\nfirst_prompt \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatPromptTemplate\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_template\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    \"What \u003cspan class=\"token keyword\"\u003eis\u003c/span\u003e the best name to describe \\\n    a company that makes \u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003eproduct\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e?\"\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# Chain 1\u003c/span\u003e\nchain_one \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e LLMChain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ellm\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ellm\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e prompt\u003cspan class=\"token operator\"\u003e=\u003c/span\u003efirst_prompt\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# prompt template 2\u003c/span\u003e\nsecond_prompt \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatPromptTemplate\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_template\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    \"Write a \u003cspan class=\"token number\"\u003e20\u003c/span\u003e words description \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e the following \\\n    company\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003ecompany_name\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\"\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# chain 2\u003c/span\u003e\nchain_two \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e LLMChain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ellm\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ellm\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e prompt\u003cspan class=\"token operator\"\u003e=\u003c/span\u003esecond_prompt\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\noverall_simple_chain \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e SimpleSequentialChain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003echains\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003echain_one\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e chain_two\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\noverall_simple_chain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erun\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eproduct\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSequentialChain\u003c/strong\u003e\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003echains \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e SequentialChain\nllm \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatOpenAI\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etemperature\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.9\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e model\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ellm_model\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# prompt template 1: translate to english\u003c/span\u003e\nfirst_prompt \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatPromptTemplate\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_template\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"Translate the following review to english:\"\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"\\n\\n{Review}\"\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# chain 1: input= Review and output= English_Review\u003c/span\u003e\nchain_one \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e LLMChain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ellm\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ellm\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e prompt\u003cspan class=\"token operator\"\u003e=\u003c/span\u003efirst_prompt\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \n                     output_key\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"English_Review\"\u003c/span\u003e\n                    \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nsecond_prompt \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatPromptTemplate\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_template\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"Can you summarize the following review in 1 sentence:\"\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"\\n\\n{English_Review}\"\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# chain 2: input= English_Review and output= summary\u003c/span\u003e\nchain_two \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e LLMChain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ellm\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ellm\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e prompt\u003cspan class=\"token operator\"\u003e=\u003c/span\u003esecond_prompt\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \n                     output_key\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"summary\"\u003c/span\u003e\n                    \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# prompt template 3: translate to english\u003c/span\u003e\nthird_prompt \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatPromptTemplate\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_template\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"What language is the following review:\\n\\n{Review}\"\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# chain 3: input= Review and output= language\u003c/span\u003e\nchain_three \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e LLMChain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ellm\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ellm\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e prompt\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ethird_prompt\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n                       output_key\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"language\"\u003c/span\u003e\n                      \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# prompt template 4: follow up message\u003c/span\u003e\nfourth_prompt \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatPromptTemplate\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_template\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"Write a follow up response to the following \"\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"summary in the specified language:\"\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# chain 4: input= summary, language and output= followup_message\u003c/span\u003e\nchain_four \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e LLMChain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ellm\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ellm\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e prompt\u003cspan class=\"token operator\"\u003e=\u003c/span\u003efourth_prompt\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n                      output_key\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"followup_message\"\u003c/span\u003e\n                     \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# overall_chain: input= Review \u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# and output= English_Review,summary, followup_message\u003c/span\u003e\noverall_chain \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e SequentialChain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    chains\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003echain_one\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e chain_two\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e chain_three\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e chain_four\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    input_variables\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"Review\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    output_variables\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"English_Review\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"summary\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"followup_message\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    verbose\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token boolean\"\u003eTrue\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nreview \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"add some review here\"\u003c/span\u003e\noverall_chain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ereview\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"router-chain\"\u003eRouter Chain\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#router-chain\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eA Router Chain is a LangChain pattern used when you don‚Äôt want one single prompt or chain to handle every input, but instead want the system to decide which chain should run based on the input.\u003c/p\u003e\n\u003cp\u003eThink of it as an LLM-powered if / else or switch statement.\n\u003cstrong\u003eThe core idea\u003c/strong\u003e : Given an input, choose the most appropriate chain to handle it.\nExample:\nIf input is a math question ‚Üí use math chain\nIf input is code-related ‚Üí use coding chain\nIf input is customer support ‚Üí use support chain\nYou route the request to the right specialist\u003c/p\u003e\n\u003ch3 id=\"key-benefits-of-using-chain\"\u003eKey benefits of using Chain\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#key-benefits-of-using-chain\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eüîπ \u003cstrong\u003e1. Prompt templating \u0026#x26; variable injection\u003c/strong\u003e\nThis becomes powerful when: Prompts are long, Variables are many, Prompts are reused across files.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eüîπ 2. Reusability \u0026#x26; maintainability\u003c/strong\u003e\nYou define the prompt once, Instead of copy-pasting prompts everywhere.\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003echain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erun\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"Queen Size Sheet Set\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erun\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"Organic Soap\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003erun\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"AI SaaS Platform\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eüîπ 3. Easy model swapping \u0026#x26; configuration\u003c/strong\u003e\nChange model/temperature without touching your logic.\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003ellm \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e ChatOpenAI\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emodel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"gpt-4\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e temperature\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.2\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eüîπ 4. Multi-step workflows (SequentialChain)\u003c/strong\u003e\nWhile an LLMChain represents a single step, real power comes from composing multiple LLMChains using SequentialChain, RouterChain, or Agents.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eüîπ 5. Composition(chains calling chains) with tools, memory, retrievers\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eChains can be stacked:\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003eUser Input\n   ‚Üì\nSummarization Chain\n   ‚Üì\nTranslation Chain\n   ‚Üì\nTone Adjustment Chain\n   ‚Üì\nFinal Output\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eChains can integrate: üîç Vector databases, üß† Conversation memory, üõ†Ô∏è Tools \u0026#x26; function calling, üîÑ Retries \u0026#x26; fallback models, üìä Tracing \u0026#x26; observability\u003c/p\u003e\n\u003cp\u003eExample:\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\nUser Question\n   ‚Üì\nRetrieve relevant docs\n   ‚Üì\nInsert into prompt\n   ‚Üì\nLLM answers \u003cspan class=\"token keyword\"\u003ewith\u003c/span\u003e citations\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis is the backbone of RAG (Retrieval-Augmented Generation).\u003c/p\u003e\n\u003ch2 id=\"retrieval-rag\"\u003eRetrieval (RAG)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#retrieval-rag\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eLangChain makes it easy to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLoad documents (PDFs, Notion, websites)\u003c/li\u003e\n\u003cli\u003eEmbed them into vectors\u003c/li\u003e\n\u003cli\u003eStore them in a vector database\u003c/li\u003e\n\u003cli\u003eRetrieve relevant chunks\u003c/li\u003e\n\u003cli\u003eInject them into the prompt\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis pattern is called \u003cstrong\u003eRetrieval-Augmented Generation (RAG)\u003c/strong\u003e.\u003c/p\u003e\n\u003ch3 id=\"common-components-of-ragretrieval-augmented-generation\"\u003eCommon components of RAG(Retrieval Augmented Generation)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#common-components-of-ragretrieval-augmented-generation\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cdiv class=\"mermaid\"\u003e\n    graph TD;\n      Data-Source--\u003eData-Transformation;\n      Data-Transformation--\u003eText-embedding;\n      Text-embedding--\u003eVectorStore-DB;\n\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eData-Ingestion\u003c/strong\u003e: (Load data into langchain/Data ingestion)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eData-Transformation\u003c/strong\u003e : (breaking data into text chunks)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eEmbedding\u003c/strong\u003e: converting text into vectors using embedding techniques. This is required for different algorithms to run(similarity serach). \u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eVectorStore-DB\u003c/strong\u003e: saving vectors into a vector DB ex: chromaDB, FAISS, ASTRADB\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe details are present in their invdiviual pages below\u003c/p\u003e\n\u003ch3 id=\"data-ingestion\"\u003eData Ingestion:\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#data-ingestion\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\"\u003elearning.langchain.document-ingestion (Private)\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"data-transformationtext-splitting\"\u003eData-Transformation(Text splitting)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#data-transformationtext-splitting\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\"\u003elearning.langchain.text-splitting (Private)\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"embeddings\"\u003eEmbeddings\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#embeddings\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003e\u003ca title=\"Private\" href=\"https://wiki.dendron.so/notes/hfyvYGJZQiUwQaaxQO27q.html\" target=\"_blank\" class=\"private\"\u003elearning.langchain.embeddings (Private)\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"tools\"\u003eTools\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#tools\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eTools can be things like:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWeb search\u003c/li\u003e\n\u003cli\u003eSQL queries\u003c/li\u003e\n\u003cli\u003ePython execution\u003c/li\u003e\n\u003cli\u003eAPIs\u003c/li\u003e\n\u003cli\u003eFile systems\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLangChain gives a standard way to expose these tools to an LLM.\u003c/p\u003e\n\u003chr\u003e\n\u003cstrong\u003eChildren\u003c/strong\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"/Frontend-JsDev-Handbook/notes/duydba1xzdaypg4p9egmt3g\"\u003eDocument Ingestion\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/Frontend-JsDev-Handbook/notes/nrx71p01v1xopk4xtim8xjb\"\u003eLLM-models\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/Frontend-JsDev-Handbook/notes/0jmd9qrvoy9orbl1n2mzxla\"\u003eSimple Gen AI APP Using Langchain\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/Frontend-JsDev-Handbook/notes/1rujyxrb9vcc5vpxg0s0o8c\"\u003eText splitting from Documents\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/Frontend-JsDev-Handbook/notes/g9anqrp0zrf7ge81edgx8yo\"\u003eVersion-1\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/Frontend-JsDev-Handbook/notes/qxj02f4em65xllkz33rnbb2\"\u003eembeddings\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/Frontend-JsDev-Handbook/notes/g8ci1ind9asxblmph23fcew\"\u003evector-store\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e","noteIndex":{"id":"dlb5bmx7v8f6otsgongz4vx","title":"Hi","desc":"","updated":1663067414354,"created":1648190029829,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"5e58da66991a53ed4cf17d0cade77fe6","links":[{"type":"wiki","from":{"fname":"root","id":"dlb5bmx7v8f6otsgongz4vx","vaultName":"Harshita-notes"},"value":"user.tharshita13","alias":"@tharshita13","position":{"start":{"line":15,"column":12,"offset":433},"end":{"line":15,"column":24,"offset":445},"indent":[]},"xvault":false,"to":{"fname":"user.tharshita13"}}],"anchors":{"contacts":{"type":"header","text":"Contacts","value":"contacts","line":13,"column":0,"depth":2}},"children":["trkx8xrg7g2fm023ez4ldqj","c8csxid3zoghxorepwcrami","urj8q1uq98o3upmgbt2qxns","ddh1fz3o9jtwlnhx8im7w6n","xjtg1so5cq4qj3qoj1n357g","wcja9b2dozrw97bjfuc1ewj"],"parent":null,"data":{},"body":"\nHi,\nWelcome to Harshita's Digital Garden üå±\nI'm Harshita Joshi. I'm a software engineer.\nWhen not at the computer, I play ukulele, do yoga, study [German](https://harshita-mindfire.github.io/german-for-beginners/) and wonder about having numerous pets.\n\n## Contacts\n\nYou can find and contact me in the following places\n\n- Email: tharshita13@gmail.com\n\n- Github: [Harshita-mindfire](https://github.com/Harshita-mindfire)\n\n- Medium: [@tharshita13](https://medium.com/@tharshita13)\n\n- LinkedIn: [Harshita Joshi](https://www.linkedin.com/in/harshita-joshi-030b29118/)\n\n- Instagram: [imharshita07](https://www.instagram.com/imharshita07/)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true,"enableEngineV3":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Digital Garden","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","siteUrl":"https://Harshita-mindfire.github.io","assetsPrefix":"/Frontend-JsDev-Handbook","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"oe485i4et1p69145l89f6zi"},"buildId":"wmlPeTCMGkfHIk3kYfq6F","assetPrefix":"/Frontend-JsDev-Handbook","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>