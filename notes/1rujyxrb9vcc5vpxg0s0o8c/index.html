<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/Frontend-JsDev-Handbook/favicon.ico"/><title>Text splitting from Documents</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal Knowledge Space"/><meta property="og:title" content="Text splitting from Documents"/><meta property="og:description" content="Personal Knowledge Space"/><meta property="og:url" content="https://Harshita-mindfire.github.io/Frontend-JsDev-Handbook/notes/1rujyxrb9vcc5vpxg0s0o8c/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="1/5/2026"/><meta property="article:modified_time" content="1/5/2026"/><link rel="canonical" href="https://Harshita-mindfire.github.io/Frontend-JsDev-Handbook/notes/1rujyxrb9vcc5vpxg0s0o8c/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/Frontend-JsDev-Handbook/_next/static/css/d70c9756212654c3.css" as="style"/><link rel="stylesheet" href="/Frontend-JsDev-Handbook/_next/static/css/d70c9756212654c3.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/Frontend-JsDev-Handbook/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/webpack-7ae598a7290a332d.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/main-99db8cbbcbcf3a6e.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/pages/_app-e77f8b0286b3a3df.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/wmlPeTCMGkfHIk3kYfq6F/_buildManifest.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/wmlPeTCMGkfHIk3kYfq6F/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="text-splitting-from-documents">Text splitting from Documents<a aria-hidden="true" class="anchor-heading icon-link" href="#text-splitting-from-documents"></a></h1>
<ul>
<li>requirements</li>
</ul>
<pre class="language-txt"><code class="language-txt">langchain-text-splitters
</code></pre>
<h2 id="recursivecharacter-text-splitters-recursivecharactertextsplitter">RecursiveCharacter Text Splitters (RecursiveCharacterTextSplitter)<a aria-hidden="true" class="anchor-heading icon-link" href="#recursivecharacter-text-splitters-recursivecharactertextsplitter"></a></h2>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> TextLoader
<span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> RecursiveCharacterTextSplitter

loader <span class="token operator">=</span> TextLoader<span class="token punctuation">(</span><span class="token string">"speech.txt"</span><span class="token punctuation">)</span>
docs <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">35</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token comment">#Use split_documents when you already have Document objects.</span>
<span class="token comment"># type(docs) ==> List[Document], hence used split_documents</span>
<span class="token comment"># Use create_documents when you have raw text. eg: if type(docs) => List[str]</span>
final_docs<span class="token operator">=</span>text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>
final_docs
</code></pre>
<p>This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is ["\n\n", "\n", " ", ""]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.</p>
<ul>
<li>How the text is split: by list of characters.</li>
<li>How the chunk size is measured: by number of characters.</li>
</ul>
<p><strong>What constraints is it trying to satisfy?</strong></p>
<p>Primarily:
-chunk_size â€“ each chunk must be â‰¤ this size
-chunk_overlap â€“ overlap between chunks</p>
<ul>
<li>Semantic preservation â€“ avoid splitting in the middle of sentences/words if possible</li>
</ul>
<p><strong>How the recursion works</strong></p>
<p>You give the splitter an ordered list of separators, for example:</p>
<pre class="language-py"><code class="language-py"><span class="token punctuation">[</span><span class="token string">"\n\n"</span><span class="token punctuation">,</span> <span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">]</span>
</code></pre>
<p>The splitter tries them in order:</p>
<ol>
<li>
<p>Try the first separator (e.g. \n\n)</p>
<ul>
<li>
<p>Does splitting by this produce chunks â‰¤ chunk_size?</p>
</li>
<li>
<p>If yes â†’ âœ… it works, stop here.</p>
</li>
</ul>
</li>
<li>
<p>If chunks are still too large â†’ recurse</p>
<ul>
<li>Try the next separator (\n)</li>
</ul>
</li>
</ol>
<p>3.Continue until a separator works</p>
<ol start="4">
<li>If nothing works â†’ fall back to <strong>character-level splitting ("")</strong></li>
</ol>
<h2 id="character-text-splitters-charactertextsplitter">Character Text Splitters (CharacterTextSplitter)<a aria-hidden="true" class="anchor-heading icon-link" href="#character-text-splitters-charactertextsplitter"></a></h2>
<p>This is the simplest method. This splits based on a given character sequence, which defaults to "\n\n". Chunk length is measured by number of characters.</p>
<ol>
<li>How the text is split: by single character separator.</li>
<li>How the chunk size is measured: by number of characters.</li>
</ol>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> TextLoader
<span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> CharacterTextSplitter

loader <span class="token operator">=</span> TextLoader<span class="token punctuation">(</span><span class="token string">"speech.txt"</span><span class="token punctuation">)</span>
docs <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#by default separator=\n\n</span>
text_splitter<span class="token operator">=</span>CharacterTextSplitter<span class="token punctuation">(</span>separator<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">,</span> chunk_size<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">)</span>
final_docs<span class="token operator">=</span>text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>
final_docs
</code></pre>
<h2 id="htmlheadertextsplitter">HTMLHeaderTextSplitter<a aria-hidden="true" class="anchor-heading icon-link" href="#htmlheadertextsplitter"></a></h2>
<p>HTMLHeaderTextSplitter is not primarily a chunk-size splitter.</p>
<p>Its job is to:</p>
<ul>
<li>Parse HTML</li>
<li>Group text by semantic structure <code>(headers like &#x3C;h1>, &#x3C;h2>)</code></li>
<li>Attach the header hierarchy as metadata</li>
</ul>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> HTMLHeaderTextSplitter
url <span class="token operator">=</span> <span class="token string">"https://plato.stanford.edu/entries/goedel/"</span>

headers_to_split_on <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"h1"</span><span class="token punctuation">,</span> <span class="token string">"Header 1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"h2"</span><span class="token punctuation">,</span> <span class="token string">"Header 2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
html_splitter <span class="token operator">=</span> HTMLHeaderTextSplitter<span class="token punctuation">(</span>headers_to_split_on<span class="token punctuation">)</span>
html_header_splits <span class="token operator">=</span> html_splitter<span class="token punctuation">.</span>split_text_from_url<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
html_header_splits
</code></pre>
<ul>
<li>Downloads the HTML from the URL</li>
<li>Parses the DOM</li>
<li>Finds <code>&#x3C;h1> / &#x3C;h2></code> tags you specified</li>
<li>Collects all text nodes that appear after a header and before the next relevant header</li>
<li>Concatenates that text into a single string</li>
<li>Stores it as Document.page_content</li>
</ul>
<h2 id="recurrsivejsonsplitter">RecurrsiveJsonSplitter<a aria-hidden="true" class="anchor-heading icon-link" href="#recurrsivejsonsplitter"></a></h2>
<p>This json splitter splits json data while allowing control over chunk sizes. It traverses json data depth first and builds smaller json chunks. It attempts to keep nested json objects whole but will split them if needed to keep chunks between a min_chunk_size and the max_chunk_size.</p>
<p>If the value is not a nested json, but rather a very large string the string will not be split. If you need a hard cap on the chunk size consider composing this with a Recursive Text splitter on those chunks. There is an optional pre-processing step to split lists, by first converting them to json (dict) and then splitting them as such.</p>
<ul>
<li>How the text is split: json value.</li>
<li>How the chunk size is measured: by number of characters.</li>
</ul>
<pre class="language-py"><code class="language-py"><span class="token keyword">import</span> json
<span class="token keyword">import</span> requests
<span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> RecursiveJsonSplitter

json_data<span class="token operator">=</span>requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"https://api.smith.langchain.com/openapi.json"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span>

json_text <span class="token operator">=</span> RecursiveJsonSplitter<span class="token punctuation">(</span>max_chunk_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
json_chunks<span class="token operator">=</span>json_text<span class="token punctuation">.</span>split_json<span class="token punctuation">(</span>json_data<span class="token punctuation">)</span>
</code></pre></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#recursivecharacter-text-splitters-recursivecharactertextsplitter" title="RecursiveCharacter Text Splitters (RecursiveCharacterTextSplitter)">RecursiveCharacter Text Splitters (RecursiveCharacterTextSplitter)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#character-text-splitters-charactertextsplitter" title="Character Text Splitters (CharacterTextSplitter)">Character Text Splitters (CharacterTextSplitter)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#htmlheadertextsplitter" title="HTMLHeaderTextSplitter">HTMLHeaderTextSplitter</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#recurrsivejsonsplitter" title="RecurrsiveJsonSplitter">RecurrsiveJsonSplitter</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"1rujyxrb9vcc5vpxg0s0o8c","title":"Text splitting from Documents","desc":"","updated":1767610546433,"created":1767610546433,"custom":{},"fname":"learning.Langchain.2-text-splitting","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"487ec68ee12f94f4675379889b01f841","links":[],"anchors":{"recursivecharacter-text-splitters-recursivecharactertextsplitter":{"type":"header","text":"RecursiveCharacter Text Splitters (RecursiveCharacterTextSplitter)","value":"recursivecharacter-text-splitters-recursivecharactertextsplitter","line":11,"column":0,"depth":2},"character-text-splitters-charactertextsplitter":{"type":"header","text":"Character Text Splitters (CharacterTextSplitter)","value":"character-text-splitters-charactertextsplitter","line":59,"column":0,"depth":2},"htmlheadertextsplitter":{"type":"header","text":"HTMLHeaderTextSplitter","value":"htmlheadertextsplitter","line":77,"column":0,"depth":2},"recurrsivejsonsplitter":{"type":"header","text":"RecurrsiveJsonSplitter","value":"recurrsivejsonsplitter","line":109,"column":0,"depth":2}},"children":[],"parent":"oe485i4et1p69145l89f6zi","data":{}},"body":"\u003ch1 id=\"text-splitting-from-documents\"\u003eText splitting from Documents\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#text-splitting-from-documents\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003erequirements\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-txt\"\u003e\u003ccode class=\"language-txt\"\u003elangchain-text-splitters\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"recursivecharacter-text-splitters-recursivecharactertextsplitter\"\u003eRecursiveCharacter Text Splitters (RecursiveCharacterTextSplitter)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#recursivecharacter-text-splitters-recursivecharactertextsplitter\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_community\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003edocument_loaders \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e TextLoader\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_text_splitters \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e RecursiveCharacterTextSplitter\n\nloader \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e TextLoader\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"speech.txt\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ndocs \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e loader\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eload\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ntext_splitter \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e RecursiveCharacterTextSplitter\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003echunk_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e35\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e chunk_overlap\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e10\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e#Use split_documents when you already have Document objects.\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# type(docs) ==\u003e List[Document], hence used split_documents\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# Use create_documents when you have raw text. eg: if type(docs) =\u003e List[str]\u003c/span\u003e\nfinal_docs\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etext_splitter\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esplit_documents\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003edocs\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nfinal_docs\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHow the text is split: by list of characters.\u003c/li\u003e\n\u003cli\u003eHow the chunk size is measured: by number of characters.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eWhat constraints is it trying to satisfy?\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003ePrimarily:\n-chunk_size â€“ each chunk must be â‰¤ this size\n-chunk_overlap â€“ overlap between chunks\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSemantic preservation â€“ avoid splitting in the middle of sentences/words if possible\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eHow the recursion works\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eYou give the splitter an ordered list of separators, for example:\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"\\n\\n\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"\\n\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e\" \"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe splitter tries them in order:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eTry the first separator (e.g. \\n\\n)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eDoes splitting by this produce chunks â‰¤ chunk_size?\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf yes â†’ âœ… it works, stop here.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIf chunks are still too large â†’ recurse\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTry the next separator (\\n)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e3.Continue until a separator works\u003c/p\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eIf nothing works â†’ fall back to \u003cstrong\u003echaracter-level splitting (\"\")\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"character-text-splitters-charactertextsplitter\"\u003eCharacter Text Splitters (CharacterTextSplitter)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#character-text-splitters-charactertextsplitter\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eThis is the simplest method. This splits based on a given character sequence, which defaults to \"\\n\\n\". Chunk length is measured by number of characters.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eHow the text is split: by single character separator.\u003c/li\u003e\n\u003cli\u003eHow the chunk size is measured: by number of characters.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_community\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003edocument_loaders \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e TextLoader\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_text_splitters \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e CharacterTextSplitter\n\nloader \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e TextLoader\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"speech.txt\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ndocs \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e loader\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eload\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e#by default separator=\\n\\n\u003c/span\u003e\ntext_splitter\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eCharacterTextSplitter\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eseparator\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\" \"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e chunk_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e40\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e chunk_overlap\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e15\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nfinal_docs\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etext_splitter\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esplit_documents\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003edocs\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nfinal_docs\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"htmlheadertextsplitter\"\u003eHTMLHeaderTextSplitter\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#htmlheadertextsplitter\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eHTMLHeaderTextSplitter is not primarily a chunk-size splitter.\u003c/p\u003e\n\u003cp\u003eIts job is to:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eParse HTML\u003c/li\u003e\n\u003cli\u003eGroup text by semantic structure \u003ccode\u003e(headers like \u0026#x3C;h1\u003e, \u0026#x3C;h2\u003e)\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eAttach the header hierarchy as metadata\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_text_splitters \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e HTMLHeaderTextSplitter\nurl \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"https://plato.stanford.edu/entries/goedel/\"\u003c/span\u003e\n\nheaders_to_split_on \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"h1\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"Header 1\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"h2\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"Header 2\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\nhtml_splitter \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e HTMLHeaderTextSplitter\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eheaders_to_split_on\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nhtml_header_splits \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e html_splitter\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esplit_text_from_url\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eurl\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nhtml_header_splits\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eDownloads the HTML from the URL\u003c/li\u003e\n\u003cli\u003eParses the DOM\u003c/li\u003e\n\u003cli\u003eFinds \u003ccode\u003e\u0026#x3C;h1\u003e / \u0026#x3C;h2\u003e\u003c/code\u003e tags you specified\u003c/li\u003e\n\u003cli\u003eCollects all text nodes that appear after a header and before the next relevant header\u003c/li\u003e\n\u003cli\u003eConcatenates that text into a single string\u003c/li\u003e\n\u003cli\u003eStores it as Document.page_content\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"recurrsivejsonsplitter\"\u003eRecurrsiveJsonSplitter\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#recurrsivejsonsplitter\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eThis json splitter splits json data while allowing control over chunk sizes. It traverses json data depth first and builds smaller json chunks. It attempts to keep nested json objects whole but will split them if needed to keep chunks between a min_chunk_size and the max_chunk_size.\u003c/p\u003e\n\u003cp\u003eIf the value is not a nested json, but rather a very large string the string will not be split. If you need a hard cap on the chunk size consider composing this with a Recursive Text splitter on those chunks. There is an optional pre-processing step to split lists, by first converting them to json (dict) and then splitting them as such.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHow the text is split: json value.\u003c/li\u003e\n\u003cli\u003eHow the chunk size is measured: by number of characters.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e json\n\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e requests\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_text_splitters \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e RecursiveJsonSplitter\n\njson_data\u003cspan class=\"token operator\"\u003e=\u003c/span\u003erequests\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eget\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"https://api.smith.langchain.com/openapi.json\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ejson\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\njson_text \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e RecursiveJsonSplitter\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emax_chunk_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e100\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\njson_chunks\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ejson_text\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esplit_json\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ejson_data\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e","noteIndex":{"id":"dlb5bmx7v8f6otsgongz4vx","title":"Hi","desc":"","updated":1663067414354,"created":1648190029829,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"5e58da66991a53ed4cf17d0cade77fe6","links":[{"type":"wiki","from":{"fname":"root","id":"dlb5bmx7v8f6otsgongz4vx","vaultName":"Harshita-notes"},"value":"user.tharshita13","alias":"@tharshita13","position":{"start":{"line":15,"column":12,"offset":433},"end":{"line":15,"column":24,"offset":445},"indent":[]},"xvault":false,"to":{"fname":"user.tharshita13"}}],"anchors":{"contacts":{"type":"header","text":"Contacts","value":"contacts","line":13,"column":0,"depth":2}},"children":["trkx8xrg7g2fm023ez4ldqj","c8csxid3zoghxorepwcrami","urj8q1uq98o3upmgbt2qxns","ddh1fz3o9jtwlnhx8im7w6n","xjtg1so5cq4qj3qoj1n357g","wcja9b2dozrw97bjfuc1ewj"],"parent":null,"data":{},"body":"\nHi,\nWelcome to Harshita's Digital Garden ðŸŒ±\nI'm Harshita Joshi. I'm a software engineer.\nWhen not at the computer, I play ukulele, do yoga, study [German](https://harshita-mindfire.github.io/german-for-beginners/) and wonder about having numerous pets.\n\n## Contacts\n\nYou can find and contact me in the following places\n\n- Email: tharshita13@gmail.com\n\n- Github: [Harshita-mindfire](https://github.com/Harshita-mindfire)\n\n- Medium: [@tharshita13](https://medium.com/@tharshita13)\n\n- LinkedIn: [Harshita Joshi](https://www.linkedin.com/in/harshita-joshi-030b29118/)\n\n- Instagram: [imharshita07](https://www.instagram.com/imharshita07/)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true,"enableEngineV3":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Digital Garden","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","siteUrl":"https://Harshita-mindfire.github.io","assetsPrefix":"/Frontend-JsDev-Handbook","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"1rujyxrb9vcc5vpxg0s0o8c"},"buildId":"wmlPeTCMGkfHIk3kYfq6F","assetPrefix":"/Frontend-JsDev-Handbook","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>