<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/Frontend-JsDev-Handbook/favicon.ico"/><title>embeddings</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal Knowledge Space"/><meta property="og:title" content="embeddings"/><meta property="og:description" content="Personal Knowledge Space"/><meta property="og:url" content="https://Harshita-mindfire.github.io/Frontend-JsDev-Handbook/notes/qxj02f4em65xllkz33rnbb2/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="1/7/2026"/><meta property="article:modified_time" content="1/7/2026"/><link rel="canonical" href="https://Harshita-mindfire.github.io/Frontend-JsDev-Handbook/notes/qxj02f4em65xllkz33rnbb2/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/Frontend-JsDev-Handbook/_next/static/css/d70c9756212654c3.css" as="style"/><link rel="stylesheet" href="/Frontend-JsDev-Handbook/_next/static/css/d70c9756212654c3.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/Frontend-JsDev-Handbook/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/webpack-7ae598a7290a332d.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/main-99db8cbbcbcf3a6e.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/pages/_app-e77f8b0286b3a3df.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/wmlPeTCMGkfHIk3kYfq6F/_buildManifest.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/wmlPeTCMGkfHIk3kYfq6F/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="embeddings">embeddings<a aria-hidden="true" class="anchor-heading icon-link" href="#embeddings"></a></h1>
<p>Converting text into vectors(numerical form)</p>
<h2 id="open-ai">OPEN AI<a aria-hidden="true" class="anchor-heading icon-link" href="#open-ai"></a></h2>
<ul>
<li>OPENAI embedding documentation: <a href="https://platform.openai.com/docs/guides/embeddings">https://platform.openai.com/docs/guides/embeddings</a></li>
</ul>
<pre class="language-py"><code class="language-py"><span class="token keyword">import</span> os
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv
load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#load all the environment variables</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">]</span><span class="token operator">=</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAIEmbeddings
embeddings<span class="token operator">=</span>OpenAIEmbeddings<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"text-embedding-3-large"</span><span class="token punctuation">)</span>
embeddings

text<span class="token operator">=</span><span class="token string">"This is a tutorial on OPENAI embedding"</span>
query_result<span class="token operator">=</span>embeddings<span class="token punctuation">.</span>embed_query<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>query_result<span class="token punctuation">)</span> <span class="token comment">#3072</span>

<span class="token comment"># giving dimension of 1024</span>
embeddings_1024<span class="token operator">=</span>OpenAIEmbeddings<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"text-embedding-3-large"</span><span class="token punctuation">,</span>dimensions<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">)</span> 

text<span class="token operator">=</span><span class="token string">"This is a tutorial on OPENAI embedding"</span>
query_result<span class="token operator">=</span>embeddings_1024<span class="token punctuation">.</span>embed_query<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>query_result<span class="token punctuation">)</span> <span class="token comment">#query_result is the embedding</span>
</code></pre>
<p><strong>Full workflow</strong></p>
<ul>
<li>data ingestion</li>
</ul>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> TextLoader

loader<span class="token operator">=</span>TextLoader<span class="token punctuation">(</span><span class="token string">'speech.txt'</span><span class="token punctuation">)</span>
docs<span class="token operator">=</span>loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<ul>
<li>data splitting</li>
</ul>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> RecursiveCharacterTextSplitter

text_splitter<span class="token operator">=</span>RecursiveCharacterTextSplitter<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>chunk_overlap<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
final_documents<span class="token operator">=</span>text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>
</code></pre>
<ul>
<li>Vector Embedding And Vector StoreDB</li>
</ul>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAIEmbeddings
<span class="token comment">#needs open ai api key</span>
<span class="token comment">#requires chromadb to be added to requiremnet.txt</span>

embeddings<span class="token operator">=</span>OpenAIEmbeddings<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"text-embedding-3-large"</span><span class="token punctuation">,</span>dimensions<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">)</span> 

db<span class="token operator">=</span>Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>final_documents<span class="token punctuation">,</span>embeddings<span class="token punctuation">)</span>
</code></pre>
<ul>
<li>Retrieve the results from query vectorstore db</li>
</ul>
<pre class="language-py"><code class="language-py">query<span class="token operator">=</span><span class="token string">"It will be all the easier for us to conduct ourselves as belligerents"</span>
retrieved_results<span class="token operator">=</span>db<span class="token punctuation">.</span>similarity_search<span class="token punctuation">(</span>query<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>retrieved_results<span class="token punctuation">)</span>
</code></pre>
<h2 id="olama">OLAMA<a aria-hidden="true" class="anchor-heading icon-link" href="#olama"></a></h2>
<p>Platform where we can use open source LLM models like Llama 3, gemma etc.</p>
<ul>
<li>
<p>can run in local
<a href="https://ollama.com/blog/embedding-models">https://ollama.com/blog/embedding-models</a></p>
</li>
<li>
<p>Pull in the embedding model you want to use: </p>
</li>
</ul>
<pre class="language-txt"><code class="language-txt">ollama pull mxbai-embed-large
</code></pre>
<ul>
<li>run the curl command to see if the image is present</li>
</ul>
<pre class="language-txt"><code class="language-txt">curl http://localhost:11434/api/embeddings -d '{
  "model": "mxbai-embed-large",
  "prompt": "Represent this sentence for searching relevant passages: The sky is blue because of Rayleigh scattering"
}'
</code></pre>
<ul>
<li>create embeddings</li>
</ul>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OllamaEmbeddings
embeddings <span class="token operator">=</span> OllamaEmbeddings<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"mxbai-embed-large"</span><span class="token punctuation">)</span>

<span class="token comment">#embed_documents= list of query</span>
r1<span class="token operator">=</span>embeddings<span class="token punctuation">.</span>embed_documents<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
       <span class="token string">"Alpha is the first letter of Greek alphabet"</span><span class="token punctuation">,</span>
       <span class="token string">"Beta is the second letter of Greek alphabet"</span><span class="token punctuation">,</span> 
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token comment"># embed_query</span>
text <span class="token operator">=</span> <span class="token string">"This is a test document."</span>
query_result <span class="token operator">=</span> embeddings<span class="token punctuation">.</span>embed_query<span class="token punctuation">(</span>text<span class="token punctuation">)</span>

<span class="token comment">#query_result and r1 are vectors of 1024 dimension.</span>
</code></pre>
<h2 id="huggingface">HuggingFace<a aria-hidden="true" class="anchor-heading icon-link" href="#huggingface"></a></h2>
<p><a href="https://huggingface.co/">https://huggingface.co/</a></p>
<pre class="language-py"><code class="language-py"><span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv<span class="token punctuation">,</span> find_dotenv
<span class="token keyword">import</span> os
load_dotenv<span class="token punctuation">(</span>find_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"HF_token"</span><span class="token punctuation">]</span> <span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">"HF_token"</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain_huggingface <span class="token keyword">import</span> HuggingFaceEmbeddings
embeddings<span class="token operator">=</span>HuggingFaceEmbeddings<span class="token punctuation">(</span>model_name<span class="token operator">=</span><span class="token string">"all-MiniLM-L6-v2"</span><span class="token punctuation">)</span>

query_result<span class="token operator">=</span>embeddings<span class="token punctuation">.</span>embed_query<span class="token punctuation">(</span><span class="token string">"This is a test document"</span><span class="token punctuation">)</span> <span class="token comment">#vector embedding for this text</span>

docs_result<span class="token operator">=</span>embeddings<span class="token punctuation">.</span>embed_documents<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"This is document 1"</span><span class="token punctuation">,</span><span class="token string">"This is a test document"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#vector embeddings for both the list items</span>
docs_result<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

</code></pre></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#open-ai" title="OPEN AI">OPEN AI</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#olama" title="OLAMA">OLAMA</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#huggingface" title="HuggingFace">HuggingFace</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"qxj02f4em65xllkz33rnbb2","title":"embeddings","desc":"","updated":1767780289791,"created":1767780289791,"custom":{},"fname":"learning.Langchain.3-embeddings","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"32cab207839fe7ffbb0e4a6d0f01d3e7","links":[],"anchors":{"open-ai":{"type":"header","text":"OPEN AI","value":"open-ai","line":9,"column":0,"depth":2},"olama":{"type":"header","text":"OLAMA","value":"olama","line":72,"column":0,"depth":2},"huggingface":{"type":"header","text":"HuggingFace","value":"huggingface","line":110,"column":0,"depth":2}},"children":[],"parent":"oe485i4et1p69145l89f6zi","data":{}},"body":"\u003ch1 id=\"embeddings\"\u003eembeddings\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#embeddings\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eConverting text into vectors(numerical form)\u003c/p\u003e\n\u003ch2 id=\"open-ai\"\u003eOPEN AI\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#open-ai\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eOPENAI embedding documentation: \u003ca href=\"https://platform.openai.com/docs/guides/embeddings\"\u003ehttps://platform.openai.com/docs/guides/embeddings\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e os\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e dotenv \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e load_dotenv\nload_dotenv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e  \u003cspan class=\"token comment\"\u003e#load all the environment variables\u003c/span\u003e\nos\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eenviron\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"OPENAI_API_KEY\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eos\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003egetenv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"OPENAI_API_KEY\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e OpenAIEmbeddings\nembeddings\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eOpenAIEmbeddings\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emodel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"text-embedding-3-large\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nembeddings\n\ntext\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"This is a tutorial on OPENAI embedding\"\u003c/span\u003e\nquery_result\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eembeddings\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eembed_query\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etext\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token builtin\"\u003elen\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003equery_result\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#3072\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# giving dimension of 1024\u003c/span\u003e\nembeddings_1024\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eOpenAIEmbeddings\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emodel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"text-embedding-3-large\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003edimensions\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1024\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \n\ntext\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"This is a tutorial on OPENAI embedding\"\u003c/span\u003e\nquery_result\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eembeddings_1024\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eembed_query\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etext\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token builtin\"\u003elen\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003equery_result\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#query_result is the embedding\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eFull workflow\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003edata ingestion\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_community\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003edocument_loaders \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e TextLoader\n\nloader\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eTextLoader\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e'speech.txt'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ndocs\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloader\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eload\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003edata splitting\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_text_splitters \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e RecursiveCharacterTextSplitter\n\ntext_splitter\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eRecursiveCharacterTextSplitter\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003echunk_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e500\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003echunk_overlap\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e50\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nfinal_documents\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etext_splitter\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esplit_documents\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003edocs\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eVector Embedding And Vector StoreDB\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_community\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003evectorstores \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e Chroma\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e OpenAIEmbeddings\n\u003cspan class=\"token comment\"\u003e#needs open ai api key\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e#requires chromadb to be added to requiremnet.txt\u003c/span\u003e\n\nembeddings\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eOpenAIEmbeddings\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emodel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"text-embedding-3-large\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003edimensions\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1024\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \n\ndb\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eChroma\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_documents\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003efinal_documents\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eembeddings\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eRetrieve the results from query vectorstore db\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003equery\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"It will be all the easier for us to conduct ourselves as belligerents\"\u003c/span\u003e\nretrieved_results\u003cspan class=\"token operator\"\u003e=\u003c/span\u003edb\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esimilarity_search\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003equery\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003eprint\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eretrieved_results\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"olama\"\u003eOLAMA\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#olama\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003ePlatform where we can use open source LLM models like Llama 3, gemma etc.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ecan run in local\n\u003ca href=\"https://ollama.com/blog/embedding-models\"\u003ehttps://ollama.com/blog/embedding-models\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePull in the embedding model you want to use: \u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-txt\"\u003e\u003ccode class=\"language-txt\"\u003eollama pull mxbai-embed-large\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003erun the curl command to see if the image is present\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-txt\"\u003e\u003ccode class=\"language-txt\"\u003ecurl http://localhost:11434/api/embeddings -d '{\n  \"model\": \"mxbai-embed-large\",\n  \"prompt\": \"Represent this sentence for searching relevant passages: The sky is blue because of Rayleigh scattering\"\n}'\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003ecreate embeddings\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_community\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eembeddings \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e OllamaEmbeddings\nembeddings \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e OllamaEmbeddings\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emodel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"mxbai-embed-large\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e#embed_documents= list of query\u003c/span\u003e\nr1\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eembeddings\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eembed_documents\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\n       \u003cspan class=\"token string\"\u003e\"Alpha is the first letter of Greek alphabet\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n       \u003cspan class=\"token string\"\u003e\"Beta is the second letter of Greek alphabet\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \n    \u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# embed_query\u003c/span\u003e\ntext \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"This is a test document.\"\u003c/span\u003e\nquery_result \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e embeddings\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eembed_query\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003etext\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e#query_result and r1 are vectors of 1024 dimension.\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"huggingface\"\u003eHuggingFace\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#huggingface\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/\"\u003ehttps://huggingface.co/\u003c/a\u003e\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e dotenv \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e load_dotenv\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e find_dotenv\n\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e os\nload_dotenv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003efind_dotenv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nos\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eenviron\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"HF_token\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e os\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003egetenv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"HF_token\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_huggingface \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e HuggingFaceEmbeddings\nembeddings\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eHuggingFaceEmbeddings\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emodel_name\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"all-MiniLM-L6-v2\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nquery_result\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eembeddings\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eembed_query\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"This is a test document\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#vector embedding for this text\u003c/span\u003e\n\ndocs_result\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eembeddings\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eembed_documents\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"This is document 1\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"This is a test document\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#vector embeddings for both the list items\u003c/span\u003e\ndocs_result\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token number\"\u003e1\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e","noteIndex":{"id":"dlb5bmx7v8f6otsgongz4vx","title":"Hi","desc":"","updated":1663067414354,"created":1648190029829,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"5e58da66991a53ed4cf17d0cade77fe6","links":[{"type":"wiki","from":{"fname":"root","id":"dlb5bmx7v8f6otsgongz4vx","vaultName":"Harshita-notes"},"value":"user.tharshita13","alias":"@tharshita13","position":{"start":{"line":15,"column":12,"offset":433},"end":{"line":15,"column":24,"offset":445},"indent":[]},"xvault":false,"to":{"fname":"user.tharshita13"}}],"anchors":{"contacts":{"type":"header","text":"Contacts","value":"contacts","line":13,"column":0,"depth":2}},"children":["trkx8xrg7g2fm023ez4ldqj","c8csxid3zoghxorepwcrami","urj8q1uq98o3upmgbt2qxns","ddh1fz3o9jtwlnhx8im7w6n","xjtg1so5cq4qj3qoj1n357g","wcja9b2dozrw97bjfuc1ewj"],"parent":null,"data":{},"body":"\nHi,\nWelcome to Harshita's Digital Garden ðŸŒ±\nI'm Harshita Joshi. I'm a software engineer.\nWhen not at the computer, I play ukulele, do yoga, study [German](https://harshita-mindfire.github.io/german-for-beginners/) and wonder about having numerous pets.\n\n## Contacts\n\nYou can find and contact me in the following places\n\n- Email: tharshita13@gmail.com\n\n- Github: [Harshita-mindfire](https://github.com/Harshita-mindfire)\n\n- Medium: [@tharshita13](https://medium.com/@tharshita13)\n\n- LinkedIn: [Harshita Joshi](https://www.linkedin.com/in/harshita-joshi-030b29118/)\n\n- Instagram: [imharshita07](https://www.instagram.com/imharshita07/)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true,"enableEngineV3":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Digital Garden","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","siteUrl":"https://Harshita-mindfire.github.io","assetsPrefix":"/Frontend-JsDev-Handbook","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"qxj02f4em65xllkz33rnbb2"},"buildId":"wmlPeTCMGkfHIk3kYfq6F","assetPrefix":"/Frontend-JsDev-Handbook","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>