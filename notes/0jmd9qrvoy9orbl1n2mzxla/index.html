<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/Frontend-JsDev-Handbook/favicon.ico"/><title>Simple Gen AI APP Using Langchain</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal Knowledge Space"/><meta property="og:title" content="Simple Gen AI APP Using Langchain"/><meta property="og:description" content="Personal Knowledge Space"/><meta property="og:url" content="https://Harshita-mindfire.github.io/Frontend-JsDev-Handbook/notes/0jmd9qrvoy9orbl1n2mzxla/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="1/19/2026"/><meta property="article:modified_time" content="1/19/2026"/><link rel="canonical" href="https://Harshita-mindfire.github.io/Frontend-JsDev-Handbook/notes/0jmd9qrvoy9orbl1n2mzxla/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/Frontend-JsDev-Handbook/_next/static/css/d70c9756212654c3.css" as="style"/><link rel="stylesheet" href="/Frontend-JsDev-Handbook/_next/static/css/d70c9756212654c3.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/Frontend-JsDev-Handbook/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/webpack-7ae598a7290a332d.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/main-99db8cbbcbcf3a6e.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/pages/_app-e77f8b0286b3a3df.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/wmlPeTCMGkfHIk3kYfq6F/_buildManifest.js" defer=""></script><script src="/Frontend-JsDev-Handbook/_next/static/wmlPeTCMGkfHIk3kYfq6F/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="simple-gen-ai-app-using-langchain">Simple Gen AI APP Using Langchain<a aria-hidden="true" class="anchor-heading icon-link" href="#simple-gen-ai-app-using-langchain"></a></h1>
<h2 id="external-project">External project<a aria-hidden="true" class="anchor-heading icon-link" href="#external-project"></a></h2>
<ul>
<li><a href="https://github.com/Harshita-mindfire/langgraph/tree/main/2-Youtube-video-summarizer">Youtube video summarizer</a></li>
</ul>
<h2 id="simple-app">Simple app<a aria-hidden="true" class="anchor-heading icon-link" href="#simple-app"></a></h2>
<pre class="language-py"><code class="language-py"><span class="token keyword">import</span> os
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv
load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">]</span><span class="token operator">=</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">)</span>
<span class="token comment">## Langsmith Tracking</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"LANGCHAIN_API_KEY"</span><span class="token punctuation">]</span><span class="token operator">=</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">"LANGCHAIN_API_KEY"</span><span class="token punctuation">)</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"LANGCHAIN_TRACING_V2"</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"true"</span>
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"LANGCHAIN_PROJECT"</span><span class="token punctuation">]</span><span class="token operator">=</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">"LANGCHAIN_PROJECT"</span><span class="token punctuation">)</span>


<span class="token comment">## Data Ingestion--From the website we need to scrape the data</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> WebBaseLoader

loader<span class="token operator">=</span>WebBaseLoader<span class="token punctuation">(</span><span class="token string">"https://docs.smith.langchain.com/tutorials/Administrators/manage_spend"</span><span class="token punctuation">)</span>
docs<span class="token operator">=</span>loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">### Load Data--> Docs-->Divide our Docuemnts into chunks dcouments-->text-->vectors-->Vector Embeddings--->Vector Store DB</span>
<span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> RecursiveCharacterTextSplitter

text_splitter<span class="token operator">=</span>RecursiveCharacterTextSplitter<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>chunk_overlap<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span>
documents<span class="token operator">=</span>text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>

<span class="token comment">## Embed</span>
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAIEmbeddings
embeddings<span class="token operator">=</span>OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">## Vectore store</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> FAISS
vectorstoredb<span class="token operator">=</span>FAISS<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">,</span>embeddings<span class="token punctuation">)</span>


<span class="token comment">## Query vector db</span>
<span class="token comment">## Query From a vector db</span>
query<span class="token operator">=</span><span class="token string">"LangSmith has two usage limits: total traces and extended"</span>
result<span class="token operator">=</span>vectorstoredb<span class="token punctuation">.</span>similarity_search<span class="token punctuation">(</span>query<span class="token punctuation">)</span>
result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content

<span class="token comment">## creating Retrieval chain using open ai model</span>

<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI
llm<span class="token operator">=</span>ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span>


<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>combine_documents <span class="token keyword">import</span> create_stuff_documents_chain
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate 

prompt<span class="token operator">=</span>ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span> <span class="token triple-quoted-string string">""" Answer the following question based only on the provided context: &#x3C;context> {context} &#x3C;/context> """</span> <span class="token punctuation">)</span> 
document_chain<span class="token operator">=</span>create_stuff_documents_chain<span class="token punctuation">(</span>llm<span class="token punctuation">,</span>prompt<span class="token punctuation">)</span> 


retriever<span class="token operator">=</span>vectorstoredb<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">### created retriever</span>

<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> create_retrieval_chain
retrieval_chain<span class="token operator">=</span>create_retrieval_chain<span class="token punctuation">(</span>retriever<span class="token punctuation">,</span>document_chain<span class="token punctuation">)</span><span class="token comment">#uses retriever as context now</span>

<span class="token comment">## Get the response form the LLM</span>
response<span class="token operator">=</span>retrieval_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"input"</span><span class="token punctuation">:</span><span class="token string">"LangSmith has two usage limits: total traces and extended"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

response<span class="token punctuation">[</span><span class="token string">'answer'</span><span class="token punctuation">]</span>
</code></pre>
<h2 id="what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them">What is the use of create_stuff_documents_chain and create_retrieval_chain. Why do we need them?<a aria-hidden="true" class="anchor-heading icon-link" href="#what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them"></a></h2>
<p>Imagine you had just a normal LLM chain:</p>
<pre class="language-py"><code class="language-py">response <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"What is LangChain?"</span><span class="token punctuation">)</span>
</code></pre>
<p>What happens? The LLM answers from its training data. It does NOT access your documents. It may hallucinate. It cannot see your vector database.</p>
<p>So this is just:
üß† LLM only
No retrieval.
No grounding.</p>
<p>What if your answer depends on:</p>
<ul>
<li>Private PDFs</li>
<li>Company documents</li>
<li>Database entries
The plain chain cannot access those. That‚Äôs why RAG exists.</li>
</ul>
<p>üîπ <strong>Now Let‚Äôs See What Each Chain Adds</strong></p>
<p>We split the problem into two responsibilities:</p>
<ul>
<li>üîé Get relevant documents</li>
<li>üß† Use those documents to answer</li>
</ul>
<p>Each chain handles one responsibility.</p>
<h3 id="1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain">1Ô∏è‚É£ create_stuff_documents_chain (aka the document combine chain)<a aria-hidden="true" class="anchor-heading icon-link" href="#1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain"></a></h3>
<p>What it does: It takes</p>
<ul>
<li>A question</li>
<li>A list of documents</li>
</ul>
<p>And:</p>
<p>‚ÄúStuffs‚Äù all document text into <code>{context}</code></p>
<p>Injects that into your prompt</p>
<p>Calls the LLM</p>
<p>Returns the generated answer</p>
<pre class="language-py"><code class="language-py"><span class="token comment">#Conceptually this is what the chain does</span>

<span class="token keyword">def</span> <span class="token function">document_chain</span><span class="token punctuation">(</span>question<span class="token punctuation">,</span> docs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    context <span class="token operator">=</span> <span class="token string">"\n\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>doc<span class="token punctuation">.</span>page_content <span class="token keyword">for</span> doc <span class="token keyword">in</span> docs<span class="token punctuation">)</span>
    
    prompt <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"""
    Answer based only on the context.

    Question:
    </span><span class="token interpolation"><span class="token punctuation">{</span>question<span class="token punctuation">}</span></span><span class="token string">

    Context:
    </span><span class="token interpolation"><span class="token punctuation">{</span>context<span class="token punctuation">}</span></span><span class="token string">
    """</span></span>
    
    <span class="token keyword">return</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>

</code></pre>
<p>So this chain replaces your plain LLM chain with:
LLM + injected document context</p>
<h3 id="2Ô∏è‚É£-create_retrieval_chain">2Ô∏è‚É£ create_retrieval_chain<a aria-hidden="true" class="anchor-heading icon-link" href="#2Ô∏è‚É£-create_retrieval_chain"></a></h3>
<p>It does:</p>
<ul>
<li>Take the question</li>
<li>Call retriever</li>
<li>Get relevant documents</li>
<li>Pass them to document_chain</li>
<li>Return final answer</li>
</ul>
<p>Conceptually:</p>
<pre class="language-py"><code class="language-py"><span class="token keyword">def</span> <span class="token function">retrieval_chain</span><span class="token punctuation">(</span>question<span class="token punctuation">)</span><span class="token punctuation">:</span>
    docs <span class="token operator">=</span> retriever<span class="token punctuation">.</span>get_relevant_documents<span class="token punctuation">(</span>question<span class="token punctuation">)</span>
    <span class="token keyword">return</span> document_chain<span class="token punctuation">(</span>question<span class="token punctuation">,</span> docs<span class="token punctuation">)</span>
</code></pre>
<p>so it replaces this manual writing to one single call</p>
<pre class="language-py"><code class="language-py">retrieval_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"input"</span><span class="token punctuation">:</span> question<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="miscellaneous">Miscellaneous<a aria-hidden="true" class="anchor-heading icon-link" href="#miscellaneous"></a></h2>
<p>One of the way to write this in LCEL is (you we really need to write in LCEL)</p>
<pre class="language-py"><code class="language-py">chain <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token punctuation">{</span>
        <span class="token string">"context"</span><span class="token punctuation">:</span> retriever<span class="token punctuation">,</span>
        <span class="token string">"question"</span><span class="token punctuation">:</span> RunnablePassthrough<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    <span class="token operator">|</span> prompt
    <span class="token operator">|</span> llm
<span class="token punctuation">)</span>
chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"What is langchain?"</span><span class="token punctuation">)</span>
</code></pre>
<p>Each runnable executes.
For input: What is langchain, The first block is this dictionary:</p>
<p><strong>Step 1</strong></p>
<pre class="language-py"><code class="language-py"><span class="token punctuation">{</span>
    <span class="token string">"context"</span><span class="token punctuation">:</span> retriever<span class="token punctuation">,</span>
    <span class="token string">"question"</span><span class="token punctuation">:</span> RunnablePassthrough<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">}</span>
</code></pre>
<p>This block runs both values in parallel with the SAME input.
So Internally this happens:</p>
<p>1A:</p>
<pre class="language-py"><code class="language-py">RunnablePassthrough<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"What is LangChain?"</span><span class="token punctuation">)</span> <span class="token comment">#output: What is langchain?</span>
<span class="token comment"># RunnablePassthrough() ‚Üí returns the input unchanged</span>
</code></pre>
<p>1B</p>
<pre class="language-py"><code class="language-py">retriever<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"What is langchain?"</span><span class="token punctuation">)</span>
<span class="token comment">#returns [Document(...), Document(...)]</span>

</code></pre>
<p><strong>Result of Step 1</strong></p>
<pre class="language-py"><code class="language-py"><span class="token punctuation">{</span>
    <span class="token string">"context"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>Document<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Document<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">"question"</span><span class="token punctuation">:</span> <span class="token string">"What is langchain?"</span>
<span class="token punctuation">}</span>
</code></pre>
<p><strong>Important: In LCEL Retriever Is a Runnable</strong>
In LCEL, a retriever is a Runnable. You‚Äôre defining a computation graph, not values. That means it behaves like:</p>
<pre><code>input ‚Üí output
</code></pre>
<p>So inside a runnable mapping:</p>
<pre class="language-py"><code class="language-py">chain <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">"context"</span><span class="token punctuation">:</span> retriever
<span class="token punctuation">}</span> <span class="token operator">|</span> prompt <span class="token operator">|</span> llm
</code></pre>
<p>Means:</p>
<pre><code>"context" = retriever.invoke(input)
</code></pre>
<p>NOT:</p>
<pre class="language-py"><code class="language-py"><span class="token string">"context"</span> <span class="token operator">=</span> retriever
</code></pre>
<p>This here below means "context" = retriever object. That literally passes the retriever object.</p>
<pre class="language-py"><code class="language-py">chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"context"</span><span class="token punctuation">:</span> retriever
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
<p><strong>STEP 2 ‚Äî Prompt Runs</strong>
The prompt template expects: {question} and {context} so in LCEL chain above  <code>| prompt</code>
is internally </p>
<pre class="language-py"><code class="language-py">prompt<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{</span>
    <span class="token string">"question"</span><span class="token punctuation">:</span> <span class="token string">"What is LangChain?"</span><span class="token punctuation">,</span>
    <span class="token string">"context"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>Document<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre>
<p>Result of Step 2</p>
<pre class="language-py"><code class="language-py"><span class="token comment">#formatted_prompt</span>
"Answer the question<span class="token punctuation">:</span> What <span class="token keyword">is</span> LangChain?
Context<span class="token punctuation">:</span>
LangChain <span class="token keyword">is</span> a framework <span class="token keyword">for</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>"
</code></pre>
<p><strong>STEP 3 ‚Äî LLM Runs</strong></p>
<p>Now that formatted prompt is passed to: <code>| llm</code></p>
<pre><code>llm.invoke(formatted_prompt)
</code></pre>
<p>Output:</p>
<pre><code>"LangChain is a framework designed to build applications using LLMs..."
</code></pre></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#external-project" title="External project">External project</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#simple-app" title="Simple app">Simple app</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them" title="What is the use of create_stuff_documents_chain and create_retrieval_chain. Why do we need them?">What is the use of create_stuff_documents_chain and create_retrieval_chain. Why do we need them?</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain" title="1Ô∏è‚É£ create_stuff_documents_chain (aka the document combine chain)">1Ô∏è‚É£ create_stuff_documents_chain (aka the document combine chain)</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#2Ô∏è‚É£-create_retrieval_chain" title="2Ô∏è‚É£ create_retrieval_chain">2Ô∏è‚É£ create_retrieval_chain</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#miscellaneous" title="Miscellaneous">Miscellaneous</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"0jmd9qrvoy9orbl1n2mzxla","title":"Simple Gen AI APP Using Langchain","desc":"","updated":1768816886326,"created":1768816886326,"custom":{},"fname":"learning.Langchain.5-SimpleApp","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"107ab098ac0e75928ebf86e72298eaa8","links":[],"anchors":{"external-project":{"type":"header","text":"External project","value":"external-project","line":8,"column":0,"depth":2},"simple-app":{"type":"header","text":"Simple app","value":"simple-app","line":11,"column":0,"depth":2},"what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them":{"type":"header","text":"What is the use of create_stuff_documents_chain and create_retrieval_chain. Why do we need them?","value":"what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them","line":76,"column":0,"depth":2},"1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain":{"type":"header","text":"1Ô∏è‚É£ create_stuff_documents_chain (aka the document combine chain)","value":"1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain","line":103,"column":0,"depth":3},"2Ô∏è‚É£-create_retrieval_chain":{"type":"header","text":"2Ô∏è‚É£ create_retrieval_chain","value":"2Ô∏è‚É£-create_retrieval_chain","line":141,"column":0,"depth":3},"miscellaneous":{"type":"header","text":"Miscellaneous","value":"miscellaneous","line":163,"column":0,"depth":2}},"children":[],"parent":"oe485i4et1p69145l89f6zi","data":{}},"body":"\u003ch1 id=\"simple-gen-ai-app-using-langchain\"\u003eSimple Gen AI APP Using Langchain\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#simple-gen-ai-app-using-langchain\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003ch2 id=\"external-project\"\u003eExternal project\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#external-project\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/Harshita-mindfire/langgraph/tree/main/2-Youtube-video-summarizer\"\u003eYoutube video summarizer\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"simple-app\"\u003eSimple app\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#simple-app\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e os\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e dotenv \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e load_dotenv\nload_dotenv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nos\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eenviron\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e'OPENAI_API_KEY'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eos\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003egetenv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"OPENAI_API_KEY\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e## Langsmith Tracking\u003c/span\u003e\nos\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eenviron\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"LANGCHAIN_API_KEY\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eos\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003egetenv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"LANGCHAIN_API_KEY\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nos\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eenviron\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"LANGCHAIN_TRACING_V2\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"true\"\u003c/span\u003e\nos\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eenviron\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"LANGCHAIN_PROJECT\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eos\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003egetenv\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"LANGCHAIN_PROJECT\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\n\u003cspan class=\"token comment\"\u003e## Data Ingestion--From the website we need to scrape the data\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_community\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003edocument_loaders \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e WebBaseLoader\n\nloader\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eWebBaseLoader\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"https://docs.smith.langchain.com/tutorials/Administrators/manage_spend\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ndocs\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eloader\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eload\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e### Load Data--\u003e Docs--\u003eDivide our Docuemnts into chunks dcouments--\u003etext--\u003evectors--\u003eVector Embeddings---\u003eVector Store DB\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_text_splitters \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e RecursiveCharacterTextSplitter\n\ntext_splitter\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eRecursiveCharacterTextSplitter\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003echunk_size\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e1000\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003echunk_overlap\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e200\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\ndocuments\u003cspan class=\"token operator\"\u003e=\u003c/span\u003etext_splitter\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esplit_documents\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003edocs\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e## Embed\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e OpenAIEmbeddings\nembeddings\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eOpenAIEmbeddings\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e## Vectore store\u003c/span\u003e\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_community\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003evectorstores \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e FAISS\nvectorstoredb\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eFAISS\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_documents\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003edocuments\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eembeddings\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\n\u003cspan class=\"token comment\"\u003e## Query vector db\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e## Query From a vector db\u003c/span\u003e\nquery\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"LangSmith has two usage limits: total traces and extended\"\u003c/span\u003e\nresult\u003cspan class=\"token operator\"\u003e=\u003c/span\u003evectorstoredb\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003esimilarity_search\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003equery\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nresult\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token number\"\u003e0\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epage_content\n\n\u003cspan class=\"token comment\"\u003e## creating Retrieval chain using open ai model\u003c/span\u003e\n\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e ChatOpenAI\nllm\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eChatOpenAI\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emodel\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"gpt-4o\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003echains\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ecombine_documents \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e create_stuff_documents_chain\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain_core\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eprompts \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e ChatPromptTemplate \n\nprompt\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eChatPromptTemplate\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_template\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e \u003cspan class=\"token triple-quoted-string string\"\u003e\"\"\" Answer the following question based only on the provided context: \u0026#x3C;context\u003e {context} \u0026#x3C;/context\u003e \"\"\"\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \ndocument_chain\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ecreate_stuff_documents_chain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003ellm\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003eprompt\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \n\n\nretriever\u003cspan class=\"token operator\"\u003e=\u003c/span\u003evectorstoredb\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eas_retriever\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e### created retriever\u003c/span\u003e\n\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e langchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003echains \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e create_retrieval_chain\nretrieval_chain\u003cspan class=\"token operator\"\u003e=\u003c/span\u003ecreate_retrieval_chain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eretriever\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003edocument_chain\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token comment\"\u003e#uses retriever as context now\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e## Get the response form the LLM\u003c/span\u003e\nresponse\u003cspan class=\"token operator\"\u003e=\u003c/span\u003eretrieval_chain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003einvoke\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"input\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"LangSmith has two usage limits: total traces and extended\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\nresponse\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e'answer'\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them\"\u003eWhat is the use of create_stuff_documents_chain and create_retrieval_chain. Why do we need them?\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eImagine you had just a normal LLM chain:\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003eresponse \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e llm\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003einvoke\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"What is LangChain?\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhat happens? The LLM answers from its training data. It does NOT access your documents. It may hallucinate. It cannot see your vector database.\u003c/p\u003e\n\u003cp\u003eSo this is just:\nüß† LLM only\nNo retrieval.\nNo grounding.\u003c/p\u003e\n\u003cp\u003eWhat if your answer depends on:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePrivate PDFs\u003c/li\u003e\n\u003cli\u003eCompany documents\u003c/li\u003e\n\u003cli\u003eDatabase entries\nThe plain chain cannot access those. That‚Äôs why RAG exists.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eüîπ \u003cstrong\u003eNow Let‚Äôs See What Each Chain Adds\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eWe split the problem into two responsibilities:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eüîé Get relevant documents\u003c/li\u003e\n\u003cli\u003eüß† Use those documents to answer\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEach chain handles one responsibility.\u003c/p\u003e\n\u003ch3 id=\"1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain\"\u003e1Ô∏è‚É£ create_stuff_documents_chain (aka the document combine chain)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eWhat it does: It takes\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eA question\u003c/li\u003e\n\u003cli\u003eA list of documents\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAnd:\u003c/p\u003e\n\u003cp\u003e‚ÄúStuffs‚Äù all document text into \u003ccode\u003e{context}\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003eInjects that into your prompt\u003c/p\u003e\n\u003cp\u003eCalls the LLM\u003c/p\u003e\n\u003cp\u003eReturns the generated answer\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token comment\"\u003e#Conceptually this is what the chain does\u003c/span\u003e\n\n\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003edocument_chain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003equestion\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e docs\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    context \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"\\n\\n\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003ejoin\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003edoc\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003epage_content \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e doc \u003cspan class=\"token keyword\"\u003ein\u003c/span\u003e docs\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \n    prompt \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token string-interpolation\"\u003e\u003cspan class=\"token string\"\u003ef\"\"\"\n    Answer based only on the context.\n\n    Question:\n    \u003c/span\u003e\u003cspan class=\"token interpolation\"\u003e\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003equestion\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"token string\"\u003e\n\n    Context:\n    \u003c/span\u003e\u003cspan class=\"token interpolation\"\u003e\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003econtext\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"token string\"\u003e\n    \"\"\"\u003c/span\u003e\u003c/span\u003e\n    \n    \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e llm\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003einvoke\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003eprompt\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSo this chain replaces your plain LLM chain with:\nLLM + injected document context\u003c/p\u003e\n\u003ch3 id=\"2Ô∏è‚É£-create_retrieval_chain\"\u003e2Ô∏è‚É£ create_retrieval_chain\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#2Ô∏è‚É£-create_retrieval_chain\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eIt does:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTake the question\u003c/li\u003e\n\u003cli\u003eCall retriever\u003c/li\u003e\n\u003cli\u003eGet relevant documents\u003c/li\u003e\n\u003cli\u003ePass them to document_chain\u003c/li\u003e\n\u003cli\u003eReturn final answer\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eConceptually:\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"token function\"\u003eretrieval_chain\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003equestion\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\n    docs \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e retriever\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003eget_relevant_documents\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003equestion\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token keyword\"\u003ereturn\u003c/span\u003e document_chain\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003equestion\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e docs\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eso it replaces this manual writing to one single call\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003eretrieval_chain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003einvoke\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"input\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e question\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"miscellaneous\"\u003eMiscellaneous\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#miscellaneous\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eOne of the way to write this in LCEL is (you we really need to write in LCEL)\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003echain \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\n        \u003cspan class=\"token string\"\u003e\"context\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e retriever\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n        \u003cspan class=\"token string\"\u003e\"question\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e RunnablePassthrough\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\n    \u003cspan class=\"token operator\"\u003e|\u003c/span\u003e prompt\n    \u003cspan class=\"token operator\"\u003e|\u003c/span\u003e llm\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nchain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003einvoke\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"What is langchain?\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eEach runnable executes.\nFor input: What is langchain, The first block is this dictionary:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStep 1\u003c/strong\u003e\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"context\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e retriever\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"question\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e RunnablePassthrough\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis block runs both values in parallel with the SAME input.\nSo Internally this happens:\u003c/p\u003e\n\u003cp\u003e1A:\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003eRunnablePassthrough\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003einvoke\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"What is LangChain?\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e \u003cspan class=\"token comment\"\u003e#output: What is langchain?\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e# RunnablePassthrough() ‚Üí returns the input unchanged\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e1B\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003eretriever\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003einvoke\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"What is langchain?\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003cspan class=\"token comment\"\u003e#returns [Document(...), Document(...)]\u003c/span\u003e\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eResult of Step 1\u003c/strong\u003e\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"context\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003eDocument\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e Document\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"question\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"What is langchain?\"\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eImportant: In LCEL Retriever Is a Runnable\u003c/strong\u003e\nIn LCEL, a retriever is a Runnable. You‚Äôre defining a computation graph, not values. That means it behaves like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003einput ‚Üí output\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSo inside a runnable mapping:\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003echain \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\n   \u003cspan class=\"token string\"\u003e\"context\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e retriever\n\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e \u003cspan class=\"token operator\"\u003e|\u003c/span\u003e prompt \u003cspan class=\"token operator\"\u003e|\u003c/span\u003e llm\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMeans:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\"context\" = retriever.invoke(input)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNOT:\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token string\"\u003e\"context\"\u003c/span\u003e \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e retriever\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis here below means \"context\" = retriever object. That literally passes the retriever object.\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003echain\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003einvoke\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"context\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e retriever\n\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSTEP 2 ‚Äî Prompt Runs\u003c/strong\u003e\nThe prompt template expects: {question} and {context} so in LCEL chain above  \u003ccode\u003e| prompt\u003c/code\u003e\nis internally \u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003eprompt\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003einvoke\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"question\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"What is LangChain?\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"context\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003eDocument\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eResult of Step 2\u003c/p\u003e\n\u003cpre class=\"language-py\"\u003e\u003ccode class=\"language-py\"\u003e\u003cspan class=\"token comment\"\u003e#formatted_prompt\u003c/span\u003e\n\"Answer the question\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e What \u003cspan class=\"token keyword\"\u003eis\u003c/span\u003e LangChain?\nContext\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e\nLangChain \u003cspan class=\"token keyword\"\u003eis\u003c/span\u003e a framework \u003cspan class=\"token keyword\"\u003efor\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003e\"\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eSTEP 3 ‚Äî LLM Runs\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eNow that formatted prompt is passed to: \u003ccode\u003e| llm\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ellm.invoke(formatted_prompt)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOutput:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\"LangChain is a framework designed to build applications using LLMs...\"\n\u003c/code\u003e\u003c/pre\u003e","noteIndex":{"id":"dlb5bmx7v8f6otsgongz4vx","title":"Hi","desc":"","updated":1663067414354,"created":1648190029829,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"5e58da66991a53ed4cf17d0cade77fe6","links":[{"type":"wiki","from":{"fname":"root","id":"dlb5bmx7v8f6otsgongz4vx","vaultName":"Harshita-notes"},"value":"user.tharshita13","alias":"@tharshita13","position":{"start":{"line":15,"column":12,"offset":433},"end":{"line":15,"column":24,"offset":445},"indent":[]},"xvault":false,"to":{"fname":"user.tharshita13"}}],"anchors":{"contacts":{"type":"header","text":"Contacts","value":"contacts","line":13,"column":0,"depth":2}},"children":["trkx8xrg7g2fm023ez4ldqj","c8csxid3zoghxorepwcrami","urj8q1uq98o3upmgbt2qxns","ddh1fz3o9jtwlnhx8im7w6n","xjtg1so5cq4qj3qoj1n357g","wcja9b2dozrw97bjfuc1ewj"],"parent":null,"data":{},"body":"\nHi,\nWelcome to Harshita's Digital Garden üå±\nI'm Harshita Joshi. I'm a software engineer.\nWhen not at the computer, I play ukulele, do yoga, study [German](https://harshita-mindfire.github.io/german-for-beginners/) and wonder about having numerous pets.\n\n## Contacts\n\nYou can find and contact me in the following places\n\n- Email: tharshita13@gmail.com\n\n- Github: [Harshita-mindfire](https://github.com/Harshita-mindfire)\n\n- Medium: [@tharshita13](https://medium.com/@tharshita13)\n\n- LinkedIn: [Harshita Joshi](https://www.linkedin.com/in/harshita-joshi-030b29118/)\n\n- Instagram: [imharshita07](https://www.instagram.com/imharshita07/)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true,"enableEngineV3":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Digital Garden","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","siteUrl":"https://Harshita-mindfire.github.io","assetsPrefix":"/Frontend-JsDev-Handbook","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"0jmd9qrvoy9orbl1n2mzxla"},"buildId":"wmlPeTCMGkfHIk3kYfq6F","assetPrefix":"/Frontend-JsDev-Handbook","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>