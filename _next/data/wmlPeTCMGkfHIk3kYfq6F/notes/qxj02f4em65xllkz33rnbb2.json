{"pageProps":{"note":{"id":"qxj02f4em65xllkz33rnbb2","title":"embeddings","desc":"","updated":1767780289791,"created":1767780289791,"custom":{},"fname":"learning.Langchain.3-embeddings","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"32cab207839fe7ffbb0e4a6d0f01d3e7","links":[],"anchors":{"open-ai":{"type":"header","text":"OPEN AI","value":"open-ai","line":9,"column":0,"depth":2},"olama":{"type":"header","text":"OLAMA","value":"olama","line":72,"column":0,"depth":2},"huggingface":{"type":"header","text":"HuggingFace","value":"huggingface","line":110,"column":0,"depth":2}},"children":[],"parent":"oe485i4et1p69145l89f6zi","data":{}},"body":"<h1 id=\"embeddings\">embeddings<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#embeddings\"></a></h1>\n<p>Converting text into vectors(numerical form)</p>\n<h2 id=\"open-ai\">OPEN AI<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#open-ai\"></a></h2>\n<ul>\n<li>OPENAI embedding documentation: <a href=\"https://platform.openai.com/docs/guides/embeddings\">https://platform.openai.com/docs/guides/embeddings</a></li>\n</ul>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">from</span> dotenv <span class=\"token keyword\">import</span> load_dotenv\nload_dotenv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\">#load all the environment variables</span>\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">from</span> langchain_openai <span class=\"token keyword\">import</span> OpenAIEmbeddings\nembeddings<span class=\"token operator\">=</span>OpenAIEmbeddings<span class=\"token punctuation\">(</span>model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-3-large\"</span><span class=\"token punctuation\">)</span>\nembeddings\n\ntext<span class=\"token operator\">=</span><span class=\"token string\">\"This is a tutorial on OPENAI embedding\"</span>\nquery_result<span class=\"token operator\">=</span>embeddings<span class=\"token punctuation\">.</span>embed_query<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n<span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>query_result<span class=\"token punctuation\">)</span> <span class=\"token comment\">#3072</span>\n\n<span class=\"token comment\"># giving dimension of 1024</span>\nembeddings_1024<span class=\"token operator\">=</span>OpenAIEmbeddings<span class=\"token punctuation\">(</span>model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-3-large\"</span><span class=\"token punctuation\">,</span>dimensions<span class=\"token operator\">=</span><span class=\"token number\">1024</span><span class=\"token punctuation\">)</span> \n\ntext<span class=\"token operator\">=</span><span class=\"token string\">\"This is a tutorial on OPENAI embedding\"</span>\nquery_result<span class=\"token operator\">=</span>embeddings_1024<span class=\"token punctuation\">.</span>embed_query<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n<span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>query_result<span class=\"token punctuation\">)</span> <span class=\"token comment\">#query_result is the embedding</span>\n</code></pre>\n<p><strong>Full workflow</strong></p>\n<ul>\n<li>data ingestion</li>\n</ul>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">from</span> langchain_community<span class=\"token punctuation\">.</span>document_loaders <span class=\"token keyword\">import</span> TextLoader\n\nloader<span class=\"token operator\">=</span>TextLoader<span class=\"token punctuation\">(</span><span class=\"token string\">'speech.txt'</span><span class=\"token punctuation\">)</span>\ndocs<span class=\"token operator\">=</span>loader<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<ul>\n<li>data splitting</li>\n</ul>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">from</span> langchain_text_splitters <span class=\"token keyword\">import</span> RecursiveCharacterTextSplitter\n\ntext_splitter<span class=\"token operator\">=</span>RecursiveCharacterTextSplitter<span class=\"token punctuation\">(</span>chunk_size<span class=\"token operator\">=</span><span class=\"token number\">500</span><span class=\"token punctuation\">,</span>chunk_overlap<span class=\"token operator\">=</span><span class=\"token number\">50</span><span class=\"token punctuation\">)</span>\nfinal_documents<span class=\"token operator\">=</span>text_splitter<span class=\"token punctuation\">.</span>split_documents<span class=\"token punctuation\">(</span>docs<span class=\"token punctuation\">)</span>\n</code></pre>\n<ul>\n<li>Vector Embedding And Vector StoreDB</li>\n</ul>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">from</span> langchain_community<span class=\"token punctuation\">.</span>vectorstores <span class=\"token keyword\">import</span> Chroma\n<span class=\"token keyword\">from</span> langchain_openai <span class=\"token keyword\">import</span> OpenAIEmbeddings\n<span class=\"token comment\">#needs open ai api key</span>\n<span class=\"token comment\">#requires chromadb to be added to requiremnet.txt</span>\n\nembeddings<span class=\"token operator\">=</span>OpenAIEmbeddings<span class=\"token punctuation\">(</span>model<span class=\"token operator\">=</span><span class=\"token string\">\"text-embedding-3-large\"</span><span class=\"token punctuation\">,</span>dimensions<span class=\"token operator\">=</span><span class=\"token number\">1024</span><span class=\"token punctuation\">)</span> \n\ndb<span class=\"token operator\">=</span>Chroma<span class=\"token punctuation\">.</span>from_documents<span class=\"token punctuation\">(</span>final_documents<span class=\"token punctuation\">,</span>embeddings<span class=\"token punctuation\">)</span>\n</code></pre>\n<ul>\n<li>Retrieve the results from query vectorstore db</li>\n</ul>\n<pre class=\"language-py\"><code class=\"language-py\">query<span class=\"token operator\">=</span><span class=\"token string\">\"It will be all the easier for us to conduct ourselves as belligerents\"</span>\nretrieved_results<span class=\"token operator\">=</span>db<span class=\"token punctuation\">.</span>similarity_search<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>retrieved_results<span class=\"token punctuation\">)</span>\n</code></pre>\n<h2 id=\"olama\">OLAMA<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#olama\"></a></h2>\n<p>Platform where we can use open source LLM models like Llama 3, gemma etc.</p>\n<ul>\n<li>\n<p>can run in local\n<a href=\"https://ollama.com/blog/embedding-models\">https://ollama.com/blog/embedding-models</a></p>\n</li>\n<li>\n<p>Pull in the embedding model you want to use: </p>\n</li>\n</ul>\n<pre class=\"language-txt\"><code class=\"language-txt\">ollama pull mxbai-embed-large\n</code></pre>\n<ul>\n<li>run the curl command to see if the image is present</li>\n</ul>\n<pre class=\"language-txt\"><code class=\"language-txt\">curl http://localhost:11434/api/embeddings -d '{\n  \"model\": \"mxbai-embed-large\",\n  \"prompt\": \"Represent this sentence for searching relevant passages: The sky is blue because of Rayleigh scattering\"\n}'\n</code></pre>\n<ul>\n<li>create embeddings</li>\n</ul>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">from</span> langchain_community<span class=\"token punctuation\">.</span>embeddings <span class=\"token keyword\">import</span> OllamaEmbeddings\nembeddings <span class=\"token operator\">=</span> OllamaEmbeddings<span class=\"token punctuation\">(</span>model<span class=\"token operator\">=</span><span class=\"token string\">\"mxbai-embed-large\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#embed_documents= list of query</span>\nr1<span class=\"token operator\">=</span>embeddings<span class=\"token punctuation\">.</span>embed_documents<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">[</span>\n       <span class=\"token string\">\"Alpha is the first letter of Greek alphabet\"</span><span class=\"token punctuation\">,</span>\n       <span class=\"token string\">\"Beta is the second letter of Greek alphabet\"</span><span class=\"token punctuation\">,</span> \n    <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># embed_query</span>\ntext <span class=\"token operator\">=</span> <span class=\"token string\">\"This is a test document.\"</span>\nquery_result <span class=\"token operator\">=</span> embeddings<span class=\"token punctuation\">.</span>embed_query<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#query_result and r1 are vectors of 1024 dimension.</span>\n</code></pre>\n<h2 id=\"huggingface\">HuggingFace<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#huggingface\"></a></h2>\n<p><a href=\"https://huggingface.co/\">https://huggingface.co/</a></p>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">from</span> dotenv <span class=\"token keyword\">import</span> load_dotenv<span class=\"token punctuation\">,</span> find_dotenv\n<span class=\"token keyword\">import</span> os\nload_dotenv<span class=\"token punctuation\">(</span>find_dotenv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"HF_token\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"HF_token\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">from</span> langchain_huggingface <span class=\"token keyword\">import</span> HuggingFaceEmbeddings\nembeddings<span class=\"token operator\">=</span>HuggingFaceEmbeddings<span class=\"token punctuation\">(</span>model_name<span class=\"token operator\">=</span><span class=\"token string\">\"all-MiniLM-L6-v2\"</span><span class=\"token punctuation\">)</span>\n\nquery_result<span class=\"token operator\">=</span>embeddings<span class=\"token punctuation\">.</span>embed_query<span class=\"token punctuation\">(</span><span class=\"token string\">\"This is a test document\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#vector embedding for this text</span>\n\ndocs_result<span class=\"token operator\">=</span>embeddings<span class=\"token punctuation\">.</span>embed_documents<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"This is document 1\"</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"This is a test document\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#vector embeddings for both the list items</span>\ndocs_result<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n\n</code></pre>","noteIndex":{"id":"dlb5bmx7v8f6otsgongz4vx","title":"Hi","desc":"","updated":1663067414354,"created":1648190029829,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"5e58da66991a53ed4cf17d0cade77fe6","links":[{"type":"wiki","from":{"fname":"root","id":"dlb5bmx7v8f6otsgongz4vx","vaultName":"Harshita-notes"},"value":"user.tharshita13","alias":"@tharshita13","position":{"start":{"line":15,"column":12,"offset":433},"end":{"line":15,"column":24,"offset":445},"indent":[]},"xvault":false,"to":{"fname":"user.tharshita13"}}],"anchors":{"contacts":{"type":"header","text":"Contacts","value":"contacts","line":13,"column":0,"depth":2}},"children":["trkx8xrg7g2fm023ez4ldqj","c8csxid3zoghxorepwcrami","urj8q1uq98o3upmgbt2qxns","ddh1fz3o9jtwlnhx8im7w6n","xjtg1so5cq4qj3qoj1n357g","wcja9b2dozrw97bjfuc1ewj"],"parent":null,"data":{},"body":"\nHi,\nWelcome to Harshita's Digital Garden ðŸŒ±\nI'm Harshita Joshi. I'm a software engineer.\nWhen not at the computer, I play ukulele, do yoga, study [German](https://harshita-mindfire.github.io/german-for-beginners/) and wonder about having numerous pets.\n\n## Contacts\n\nYou can find and contact me in the following places\n\n- Email: tharshita13@gmail.com\n\n- Github: [Harshita-mindfire](https://github.com/Harshita-mindfire)\n\n- Medium: [@tharshita13](https://medium.com/@tharshita13)\n\n- LinkedIn: [Harshita Joshi](https://www.linkedin.com/in/harshita-joshi-030b29118/)\n\n- Instagram: [imharshita07](https://www.instagram.com/imharshita07/)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true,"enableEngineV3":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Digital Garden","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","siteUrl":"https://Harshita-mindfire.github.io","assetsPrefix":"/Frontend-JsDev-Handbook","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}