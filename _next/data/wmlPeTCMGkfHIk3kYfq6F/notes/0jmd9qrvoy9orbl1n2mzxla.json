{"pageProps":{"note":{"id":"0jmd9qrvoy9orbl1n2mzxla","title":"Simple Gen AI APP Using Langchain","desc":"","updated":1768816886326,"created":1768816886326,"custom":{},"fname":"learning.Langchain.5-SimpleApp","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"107ab098ac0e75928ebf86e72298eaa8","links":[],"anchors":{"external-project":{"type":"header","text":"External project","value":"external-project","line":8,"column":0,"depth":2},"simple-app":{"type":"header","text":"Simple app","value":"simple-app","line":11,"column":0,"depth":2},"what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them":{"type":"header","text":"What is the use of create_stuff_documents_chain and create_retrieval_chain. Why do we need them?","value":"what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them","line":76,"column":0,"depth":2},"1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain":{"type":"header","text":"1Ô∏è‚É£ create_stuff_documents_chain (aka the document combine chain)","value":"1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain","line":103,"column":0,"depth":3},"2Ô∏è‚É£-create_retrieval_chain":{"type":"header","text":"2Ô∏è‚É£ create_retrieval_chain","value":"2Ô∏è‚É£-create_retrieval_chain","line":141,"column":0,"depth":3},"miscellaneous":{"type":"header","text":"Miscellaneous","value":"miscellaneous","line":163,"column":0,"depth":2}},"children":[],"parent":"oe485i4et1p69145l89f6zi","data":{}},"body":"<h1 id=\"simple-gen-ai-app-using-langchain\">Simple Gen AI APP Using Langchain<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#simple-gen-ai-app-using-langchain\"></a></h1>\n<h2 id=\"external-project\">External project<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#external-project\"></a></h2>\n<ul>\n<li><a href=\"https://github.com/Harshita-mindfire/langgraph/tree/main/2-Youtube-video-summarizer\">Youtube video summarizer</a></li>\n</ul>\n<h2 id=\"simple-app\">Simple app<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#simple-app\"></a></h2>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">from</span> dotenv <span class=\"token keyword\">import</span> load_dotenv\nload_dotenv<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'OPENAI_API_KEY'</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"OPENAI_API_KEY\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">## Langsmith Tracking</span>\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"LANGCHAIN_API_KEY\"</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"LANGCHAIN_API_KEY\"</span><span class=\"token punctuation\">)</span>\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"LANGCHAIN_TRACING_V2\"</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span><span class=\"token string\">\"true\"</span>\nos<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">\"LANGCHAIN_PROJECT\"</span><span class=\"token punctuation\">]</span><span class=\"token operator\">=</span>os<span class=\"token punctuation\">.</span>getenv<span class=\"token punctuation\">(</span><span class=\"token string\">\"LANGCHAIN_PROJECT\"</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\">## Data Ingestion--From the website we need to scrape the data</span>\n<span class=\"token keyword\">from</span> langchain_community<span class=\"token punctuation\">.</span>document_loaders <span class=\"token keyword\">import</span> WebBaseLoader\n\nloader<span class=\"token operator\">=</span>WebBaseLoader<span class=\"token punctuation\">(</span><span class=\"token string\">\"https://docs.smith.langchain.com/tutorials/Administrators/manage_spend\"</span><span class=\"token punctuation\">)</span>\ndocs<span class=\"token operator\">=</span>loader<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">### Load Data--> Docs-->Divide our Docuemnts into chunks dcouments-->text-->vectors-->Vector Embeddings--->Vector Store DB</span>\n<span class=\"token keyword\">from</span> langchain_text_splitters <span class=\"token keyword\">import</span> RecursiveCharacterTextSplitter\n\ntext_splitter<span class=\"token operator\">=</span>RecursiveCharacterTextSplitter<span class=\"token punctuation\">(</span>chunk_size<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span>chunk_overlap<span class=\"token operator\">=</span><span class=\"token number\">200</span><span class=\"token punctuation\">)</span>\ndocuments<span class=\"token operator\">=</span>text_splitter<span class=\"token punctuation\">.</span>split_documents<span class=\"token punctuation\">(</span>docs<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">## Embed</span>\n<span class=\"token keyword\">from</span> langchain_openai <span class=\"token keyword\">import</span> OpenAIEmbeddings\nembeddings<span class=\"token operator\">=</span>OpenAIEmbeddings<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">## Vectore store</span>\n<span class=\"token keyword\">from</span> langchain_community<span class=\"token punctuation\">.</span>vectorstores <span class=\"token keyword\">import</span> FAISS\nvectorstoredb<span class=\"token operator\">=</span>FAISS<span class=\"token punctuation\">.</span>from_documents<span class=\"token punctuation\">(</span>documents<span class=\"token punctuation\">,</span>embeddings<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\">## Query vector db</span>\n<span class=\"token comment\">## Query From a vector db</span>\nquery<span class=\"token operator\">=</span><span class=\"token string\">\"LangSmith has two usage limits: total traces and extended\"</span>\nresult<span class=\"token operator\">=</span>vectorstoredb<span class=\"token punctuation\">.</span>similarity_search<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\nresult<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>page_content\n\n<span class=\"token comment\">## creating Retrieval chain using open ai model</span>\n\n<span class=\"token keyword\">from</span> langchain_openai <span class=\"token keyword\">import</span> ChatOpenAI\nllm<span class=\"token operator\">=</span>ChatOpenAI<span class=\"token punctuation\">(</span>model<span class=\"token operator\">=</span><span class=\"token string\">\"gpt-4o\"</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>chains<span class=\"token punctuation\">.</span>combine_documents <span class=\"token keyword\">import</span> create_stuff_documents_chain\n<span class=\"token keyword\">from</span> langchain_core<span class=\"token punctuation\">.</span>prompts <span class=\"token keyword\">import</span> ChatPromptTemplate \n\nprompt<span class=\"token operator\">=</span>ChatPromptTemplate<span class=\"token punctuation\">.</span>from_template<span class=\"token punctuation\">(</span> <span class=\"token triple-quoted-string string\">\"\"\" Answer the following question based only on the provided context: &#x3C;context> {context} &#x3C;/context> \"\"\"</span> <span class=\"token punctuation\">)</span> \ndocument_chain<span class=\"token operator\">=</span>create_stuff_documents_chain<span class=\"token punctuation\">(</span>llm<span class=\"token punctuation\">,</span>prompt<span class=\"token punctuation\">)</span> \n\n\nretriever<span class=\"token operator\">=</span>vectorstoredb<span class=\"token punctuation\">.</span>as_retriever<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">### created retriever</span>\n\n<span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>chains <span class=\"token keyword\">import</span> create_retrieval_chain\nretrieval_chain<span class=\"token operator\">=</span>create_retrieval_chain<span class=\"token punctuation\">(</span>retriever<span class=\"token punctuation\">,</span>document_chain<span class=\"token punctuation\">)</span><span class=\"token comment\">#uses retriever as context now</span>\n\n<span class=\"token comment\">## Get the response form the LLM</span>\nresponse<span class=\"token operator\">=</span>retrieval_chain<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"input\"</span><span class=\"token punctuation\">:</span><span class=\"token string\">\"LangSmith has two usage limits: total traces and extended\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\nresponse<span class=\"token punctuation\">[</span><span class=\"token string\">'answer'</span><span class=\"token punctuation\">]</span>\n</code></pre>\n<h2 id=\"what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them\">What is the use of create_stuff_documents_chain and create_retrieval_chain. Why do we need them?<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#what-is-the-use-of-create_stuff_documents_chain-and-create_retrieval_chain-why-do-we-need-them\"></a></h2>\n<p>Imagine you had just a normal LLM chain:</p>\n<pre class=\"language-py\"><code class=\"language-py\">response <span class=\"token operator\">=</span> llm<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token string\">\"What is LangChain?\"</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>What happens? The LLM answers from its training data. It does NOT access your documents. It may hallucinate. It cannot see your vector database.</p>\n<p>So this is just:\nüß† LLM only\nNo retrieval.\nNo grounding.</p>\n<p>What if your answer depends on:</p>\n<ul>\n<li>Private PDFs</li>\n<li>Company documents</li>\n<li>Database entries\nThe plain chain cannot access those. That‚Äôs why RAG exists.</li>\n</ul>\n<p>üîπ <strong>Now Let‚Äôs See What Each Chain Adds</strong></p>\n<p>We split the problem into two responsibilities:</p>\n<ul>\n<li>üîé Get relevant documents</li>\n<li>üß† Use those documents to answer</li>\n</ul>\n<p>Each chain handles one responsibility.</p>\n<h3 id=\"1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain\">1Ô∏è‚É£ create_stuff_documents_chain (aka the document combine chain)<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#1Ô∏è‚É£-create_stuff_documents_chain-aka-the-document-combine-chain\"></a></h3>\n<p>What it does: It takes</p>\n<ul>\n<li>A question</li>\n<li>A list of documents</li>\n</ul>\n<p>And:</p>\n<p>‚ÄúStuffs‚Äù all document text into <code>{context}</code></p>\n<p>Injects that into your prompt</p>\n<p>Calls the LLM</p>\n<p>Returns the generated answer</p>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token comment\">#Conceptually this is what the chain does</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">document_chain</span><span class=\"token punctuation\">(</span>question<span class=\"token punctuation\">,</span> docs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    context <span class=\"token operator\">=</span> <span class=\"token string\">\"\\n\\n\"</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>doc<span class=\"token punctuation\">.</span>page_content <span class=\"token keyword\">for</span> doc <span class=\"token keyword\">in</span> docs<span class=\"token punctuation\">)</span>\n    \n    prompt <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"\"\"\n    Answer based only on the context.\n\n    Question:\n    </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>question<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n\n    Context:\n    </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>context<span class=\"token punctuation\">}</span></span><span class=\"token string\">\n    \"\"\"</span></span>\n    \n    <span class=\"token keyword\">return</span> llm<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span>prompt<span class=\"token punctuation\">)</span>\n\n</code></pre>\n<p>So this chain replaces your plain LLM chain with:\nLLM + injected document context</p>\n<h3 id=\"2Ô∏è‚É£-create_retrieval_chain\">2Ô∏è‚É£ create_retrieval_chain<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#2Ô∏è‚É£-create_retrieval_chain\"></a></h3>\n<p>It does:</p>\n<ul>\n<li>Take the question</li>\n<li>Call retriever</li>\n<li>Get relevant documents</li>\n<li>Pass them to document_chain</li>\n<li>Return final answer</li>\n</ul>\n<p>Conceptually:</p>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token keyword\">def</span> <span class=\"token function\">retrieval_chain</span><span class=\"token punctuation\">(</span>question<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    docs <span class=\"token operator\">=</span> retriever<span class=\"token punctuation\">.</span>get_relevant_documents<span class=\"token punctuation\">(</span>question<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> document_chain<span class=\"token punctuation\">(</span>question<span class=\"token punctuation\">,</span> docs<span class=\"token punctuation\">)</span>\n</code></pre>\n<p>so it replaces this manual writing to one single call</p>\n<pre class=\"language-py\"><code class=\"language-py\">retrieval_chain<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"input\"</span><span class=\"token punctuation\">:</span> question<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<h2 id=\"miscellaneous\">Miscellaneous<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#miscellaneous\"></a></h2>\n<p>One of the way to write this in LCEL is (you we really need to write in LCEL)</p>\n<pre class=\"language-py\"><code class=\"language-py\">chain <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"context\"</span><span class=\"token punctuation\">:</span> retriever<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> RunnablePassthrough<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">}</span>\n    <span class=\"token operator\">|</span> prompt\n    <span class=\"token operator\">|</span> llm\n<span class=\"token punctuation\">)</span>\nchain<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token string\">\"What is langchain?\"</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>Each runnable executes.\nFor input: What is langchain, The first block is this dictionary:</p>\n<p><strong>Step 1</strong></p>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"context\"</span><span class=\"token punctuation\">:</span> retriever<span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> RunnablePassthrough<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p>This block runs both values in parallel with the SAME input.\nSo Internally this happens:</p>\n<p>1A:</p>\n<pre class=\"language-py\"><code class=\"language-py\">RunnablePassthrough<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token string\">\"What is LangChain?\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">#output: What is langchain?</span>\n<span class=\"token comment\"># RunnablePassthrough() ‚Üí returns the input unchanged</span>\n</code></pre>\n<p>1B</p>\n<pre class=\"language-py\"><code class=\"language-py\">retriever<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token string\">\"What is langchain?\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#returns [Document(...), Document(...)]</span>\n\n</code></pre>\n<p><strong>Result of Step 1</strong></p>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"context\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>Document<span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> Document<span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"What is langchain?\"</span>\n<span class=\"token punctuation\">}</span>\n</code></pre>\n<p><strong>Important: In LCEL Retriever Is a Runnable</strong>\nIn LCEL, a retriever is a Runnable. You‚Äôre defining a computation graph, not values. That means it behaves like:</p>\n<pre><code>input ‚Üí output\n</code></pre>\n<p>So inside a runnable mapping:</p>\n<pre class=\"language-py\"><code class=\"language-py\">chain <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n   <span class=\"token string\">\"context\"</span><span class=\"token punctuation\">:</span> retriever\n<span class=\"token punctuation\">}</span> <span class=\"token operator\">|</span> prompt <span class=\"token operator\">|</span> llm\n</code></pre>\n<p>Means:</p>\n<pre><code>\"context\" = retriever.invoke(input)\n</code></pre>\n<p>NOT:</p>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token string\">\"context\"</span> <span class=\"token operator\">=</span> retriever\n</code></pre>\n<p>This here below means \"context\" = retriever object. That literally passes the retriever object.</p>\n<pre class=\"language-py\"><code class=\"language-py\">chain<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"context\"</span><span class=\"token punctuation\">:</span> retriever\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p><strong>STEP 2 ‚Äî Prompt Runs</strong>\nThe prompt template expects: {question} and {context} so in LCEL chain above  <code>| prompt</code>\nis internally </p>\n<pre class=\"language-py\"><code class=\"language-py\">prompt<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"What is LangChain?\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"context\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>Document<span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n</code></pre>\n<p>Result of Step 2</p>\n<pre class=\"language-py\"><code class=\"language-py\"><span class=\"token comment\">#formatted_prompt</span>\n\"Answer the question<span class=\"token punctuation\">:</span> What <span class=\"token keyword\">is</span> LangChain?\nContext<span class=\"token punctuation\">:</span>\nLangChain <span class=\"token keyword\">is</span> a framework <span class=\"token keyword\">for</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\"\n</code></pre>\n<p><strong>STEP 3 ‚Äî LLM Runs</strong></p>\n<p>Now that formatted prompt is passed to: <code>| llm</code></p>\n<pre><code>llm.invoke(formatted_prompt)\n</code></pre>\n<p>Output:</p>\n<pre><code>\"LangChain is a framework designed to build applications using LLMs...\"\n</code></pre>","noteIndex":{"id":"dlb5bmx7v8f6otsgongz4vx","title":"Hi","desc":"","updated":1663067414354,"created":1648190029829,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"},"contentHash":"5e58da66991a53ed4cf17d0cade77fe6","links":[{"type":"wiki","from":{"fname":"root","id":"dlb5bmx7v8f6otsgongz4vx","vaultName":"Harshita-notes"},"value":"user.tharshita13","alias":"@tharshita13","position":{"start":{"line":15,"column":12,"offset":433},"end":{"line":15,"column":24,"offset":445},"indent":[]},"xvault":false,"to":{"fname":"user.tharshita13"}}],"anchors":{"contacts":{"type":"header","text":"Contacts","value":"contacts","line":13,"column":0,"depth":2}},"children":["trkx8xrg7g2fm023ez4ldqj","c8csxid3zoghxorepwcrami","urj8q1uq98o3upmgbt2qxns","ddh1fz3o9jtwlnhx8im7w6n","xjtg1so5cq4qj3qoj1n357g","wcja9b2dozrw97bjfuc1ewj"],"parent":null,"data":{},"body":"\nHi,\nWelcome to Harshita's Digital Garden üå±\nI'm Harshita Joshi. I'm a software engineer.\nWhen not at the computer, I play ukulele, do yoga, study [German](https://harshita-mindfire.github.io/german-for-beginners/) and wonder about having numerous pets.\n\n## Contacts\n\nYou can find and contact me in the following places\n\n- Email: tharshita13@gmail.com\n\n- Github: [Harshita-mindfire](https://github.com/Harshita-mindfire)\n\n- Medium: [@tharshita13](https://medium.com/@tharshita13)\n\n- LinkedIn: [Harshita Joshi](https://www.linkedin.com/in/harshita-joshi-030b29118/)\n\n- Instagram: [imharshita07](https://www.instagram.com/imharshita07/)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true,"enableEngineV3":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"Harshita-notes","sync":"sync"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Digital Garden","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","siteUrl":"https://Harshita-mindfire.github.io","assetsPrefix":"/Frontend-JsDev-Handbook","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}